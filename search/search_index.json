{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"PESTO : ProcESsing facTOry","text":""},{"location":"index.html#what-is-pesto","title":"What is PESTO ?","text":"<p>PESTO is a packaging tool inspired from pip, maven and similar dependencies managers. It contains shell tools to generate all the boiler plate to build an OpenAPI processing web service compliant with the  Geoprocessing-API. </p> <p>PESTO is designed to ease the process of packaging a Python algorithm as a processing web service into a docker image. The deployment of a web service becomes now as easy as filling few configuration files.</p> <p>PESTO is composed of the following components:</p> <ul> <li><code>pesto-cli</code> : the command line interface used to create a PESTO project and package processing algorithms.</li> <li><code>pesto-ws</code>: the processing web services, as docker images, created by PESTO to expose your algorithm.</li> <li><code>pesto-project</code> : the project workspace created by <code>pesto init</code> to configure the packaging process of your algorithm.</li> </ul> <p></p>"},{"location":"index.html#who-needs-pesto","title":"Who needs PESTO ?","text":"<p>PESTO was designed by data scientists and processing integrators to optimize and standardize the delivery process from the development of a analytics solution to its integration in a scalable cloud solution. Therefore, PESTO targets as well data scientists wanting their solution to be integrated in large scale solutions, as system integrators wanting to integrate and maintain up-to-date analytics solutions.</p> <p>PESTO mainly targets the implementation of a web service compliant with the Geoprocessing-API. However, it perfectly fits any image processing solution and can even be applied to any processing.</p>"},{"location":"index.html#main-features","title":"Main features","text":"<p>PESTO ships with default json schemas to define your web service API, look at <code>pesto/ressources/schema/definitions.json</code>.  But of course, you can fully tune your API by adding your own schemas.  A complementary github project was created to favor the reuse of data types definition as well as services definition, pesto-schema.</p> <p>Currently, PESTO offers following key features:</p> <ul> <li>Code generator for a standardized processing web-service,</li> <li>Synchronous / asynchronous processing,</li> <li>Embedded description of required resources for deployment in the cloud,</li> <li>Testing framework for the PESTO web service,</li> <li>Support nvidia docker for GPU accelerated computing,</li> <li>Simple interface to include you own runtime dependencies,</li> <li>Possibility to choose you root docker image for fine grained tuning of dependencies,</li> <li>Version management of web-services.</li> </ul>"},{"location":"index.html#who-uses-pesto","title":"Who uses PESTO","text":"<p>PESTO is currently used by Airbus Defense and Space / Connected Intelligence.</p> <p>PESTO is under integration by the Airbus Defense and Space / Space Systems Oasis project. It is used to integrate and manage algorithms for TM/TC analysis.</p> <p>PESTO is under integration by Airbus Defense and Space / Space Systems in its ground segment image chain.</p> <p>Workshops have been taking place with end-users in order define a solution that first could be integrated in our ground segment product lines. They have contributed to the definition of the product and have validated its integration in their own software stack.</p>"},{"location":"index.html#pesto-roadmap","title":"PESTO roadmap","text":"<p>PESTO was thought to accelerate the integration in our products of Deep Learning algorithms, being developed by Airbus or by partners. That is why, one of the first priorities is to make it open source.</p> <p>PESTO was initially designed for image processing in mind. Some specificities were then included in the runtime. Our second priority is to set up mechanisms to include user data converters as plugins and to support various Linux families.</p> <p>PESTO needs to be orchestrated. Simple tutorials and examples to deploy PESTO at scale and manage distributed processing have to be written in order to foster its acceptance by the community.</p> <p>PESTO testing and deployment framework still need additional effort to offer a complete workflow towards continuous deployment and validation.</p>"},{"location":"index.html#contacts","title":"Contacts","text":"<ul> <li> <p>Feel free to send us feedback and ask any question on github</p> </li> <li> <p>There are some advanced usage &amp; tips in the pesto cookbook.  If you find a use case that is not documented, feel free to submit a PR on github to update the documentation</p> </li> </ul>"},{"location":"deploy_run_docker_image.html","title":"Run the pesto docker image","text":"<p>If the build succeeds you should be able to see your image with the following command</p> <pre><code>docker image ls\n</code></pre> <p>Success</p> <pre><code>REPOSITORY                                                  TAG          IMAGE ID       CREATED         SIZE\nalgo-service                                                1.0.0.dev0   f04d96bb57f4   4 minutes ago   1.16GB\n</code></pre> <p>There are different ways to run the docker image of your algorithm created with <code>pesto build</code>.</p> <pre><code>pesto run docker '{\"image\":\"file:///opt/algo-service/pesto/tests/resources/test_1/input/image.png\"}' algo-service:1.0.0.dev0 /tmp/output_pesto.json\n</code></pre> <p>With this option, you can run the algorithm from a python environment where all dependencies are installed. </p> <p>Either from your local environment: <pre><code>pesto run local '{\"image\":\"file:///opt/algo-service/pesto/tests/resources/test_1/input/image.png\"}' /tmp/result.txt\n</code></pre></p> <p>Or from inside the container that has been generated: <pre><code>docker run -it --rm -v /tmp:/tmp algo-service:1.0.0.dev0 bash -c \"pesto run local '{\\\"image\\\":\\\"file:///opt/algo-service/pesto/tests/resources/test_1/input/image.png\\\"}' /tmp/result.txt\"```\n</code></pre></p> <p>You can start a container with you packaged algorithm docker image directly with docker command:</p> <pre><code>docker run --rm -p 4000:8080 algo-service:1.0.0.dev0\n</code></pre> <p>This should start the container so that it can be accessed from <code>http://localhost:4000</code>.</p> <p>You can also launch your web service as follows : </p> <pre><code>$ python {PESTO_PROJECT_ROOT}/algo_service/scripts/start_service.py\n</code></pre> <p>The webservice is by default available on the port 8080 (mapped to the port 4000 in the project) and offers the PESTO endpoints.</p>"},{"location":"deploy_run_docker_image.html#pesto-run-docker","title":"pesto run docker","text":""},{"location":"deploy_run_docker_image.html#pesto-run-local","title":"pesto run local","text":""},{"location":"deploy_run_docker_image.html#docker-run","title":"docker run","text":""},{"location":"deploy_run_docker_image.html#start-service","title":"start service","text":""},{"location":"deploy_web_service.html","title":"RestFul API Presentation","text":"<p>PESTO takes care of the API definition &amp; endpoints through the Geoprocessing API specification.</p> <p>To learn more about RESTful API, check this tutorial</p> <p>PESTO create web-services following the OpenAPI convention. </p>"},{"location":"deploy_web_service.html#pesto-endpoints","title":"PESTO endpoints","text":"<p>From a user point of view, several endpoints are defined:</p> <ul> <li><code>/api/v1/describe</code>: a GET request to get information about the packaged algorithm</li> <li><code>/api/v1/health</code>: a GET request will send back information about the </li> <li><code>/api/v1/process</code>: Send the payload (contains input data) that we want to process via a POST request</li> <li><code>api/v1/jobs</code>: a GET request to get the job list (asynchronous)</li> <li><code>api/v1/jobs/{jobID}/status</code>: a GET request to get a job status (asynchronous)</li> <li><code>api/v1/jobs/{jobID}/results</code>: a GET request to get a job result (asynchronous)</li> </ul>"},{"location":"deploy_web_service.html#describe","title":"describe","text":"<p>It provides a full description of the webservice : Required resources for deployment, Inputs, Outputs, Endpoints.</p> <pre><code>curl http://localhost:4000/api/v1/describe\n</code></pre> <p>Example</p> <pre><code>{\"name\":\"algo-service\",\"resources\":{\"cpu\":4,\"gpu\":0,\"ram\":8},\"title\":\"algo-service\",\"description\":\"Pesto Template contains all the boilerplate you need to create a processing-factory project\",\"asynchronous\":false,\"email\":\"pesto@airbus.com\",\"organization\":\"pesto\",\"family\":\"detection\",\"version\":\"1.0.0.dev0\",\"keywords\":[\"detection\"],\"template\":\"object-detection\",\"config\":{\"$schema\":\"http://json-schema.org/draft-06/schema#\",\"description\":\"Geo Process API config schema for algo-service\",\"properties\":{\"padding\":{\"description\":\"Padding / border needed to process the tile. 0 for no padding.\",\"maximum\":256,\"minimum\":0,\"type\":\"number\"},\"zoom\":{\"description\":\"Zoom levels that can be processed\",\"items\":{\"maximum\":17,\"minimum\":1,\"type\":\"number\"},\"minItems\":1,\"type\":\"array\"}},\"required\":[\"zoom\",\"padding\"],\"title\":\"tile-object-detection-config\",\"type\":\"object\"},\"input\":{\"$schema\":\"http://json-schema.org/draft-06/schema#\",\"title\":\"\",\"type\":\"object\",\"description\":\"Expected format\",\"definition\":{},\"definitions\":{\"Image\":{\"$schema\":\"http://json-schema.org/draft-06/schema#\",\"description\":\"Image to process : it can be an url or the raw bytes encoded in base64\",\"type\":\"string\"},\"Images\":{\"items\":{\"$ref\":\"#/definitions/Image\"},\"type\":\"array\"},\"Metadata\":{\"type\":\"object\"},\"Metadatas\":{\"items\":{\"$ref\":\"#/definitions/Metadata\"},\"type\":\"array\"},\"Polygon\":{\"$schema\":\"http://json-schema.org/draft-06/schema#\",\"description\":\"GeoJSON Polygon\",\"properties\":{\"bbox\":{\"items\":{\"type\":\"number\"},\"minItems\":4,\"type\":\"array\"},\"coordinates\":{\"items\":{\"items\":{\"items\":{\"type\":\"number\"},\"minItems\":2,\"type\":\"array\"},\"minItems\":4,\"type\":\"array\"},\"type\":\"array\"},\"type\":{\"enum\":[\"Polygon\"],\"type\":\"string\"}},\"required\":[\"type\",\"coordinates\"],\"title\":\"Polygon\",\"type\":\"object\"},\"Polygons\":{\"items\":{\"$ref\":\"#/definitions/Polygon\"},\"type\":\"array\"}},\"properties\":{\"dict_parameter\":{\"$ref\":\"#/definitions/Metadata\",\"description\":\"A dict parameter\"},\"image\":{\"$ref\":\"#/definitions/Image\",\"description\":\"Input image\"},\"integer_parameter\":{\"description\":\"A (integer) number parameter\",\"type\":\"integer\"},\"number_parameter\":{\"description\":\"A (floating point) number parameter\",\"type\":\"number\"},\"object_parameter\":{\"description\":\"A dict parameter with more spec, of the form {'key':'value'}\",\"properties\":{\"key\":{\"type\":\"string\"}},\"type\":\"object\"},\"string_parameter\":{\"description\":\"A string parameter\",\"type\":\"string\"}},\"required\":[\"image\"]},\"output\":{\"$schema\":\"http://json-schema.org/draft-06/schema#\",\"title\":\"\",\"type\":\"object\",\"description\":\"Expected format\",\"definition\":{},\"definitions\":{\"Image\":{\"$schema\":\"http://json-schema.org/draft-06/schema#\",\"description\":\"Image to process : it can be an url or the raw bytes encoded in base64\",\"type\":\"string\"},\"Images\":{\"items\":{\"$ref\":\"#/definitions/Image\"},\"type\":\"array\"},\"Metadata\":{\"type\":\"object\"},\"Metadatas\":{\"items\":{\"$ref\":\"#/definitions/Metadata\"},\"type\":\"array\"},\"Polygon\":{\"$schema\":\"http://json-schema.org/draft-06/schema#\",\"description\":\"GeoJSON Polygon\",\"properties\":{\"bbox\":{\"items\":{\"type\":\"number\"},\"minItems\":4,\"type\":\"array\"},\"coordinates\":{\"items\":{\"items\":{\"items\":{\"type\":\"number\"},\"minItems\":2,\"type\":\"array\"},\"minItems\":4,\"type\":\"array\"},\"type\":\"array\"},\"type\":{\"enum\":[\"Polygon\"],\"type\":\"string\"}},\"required\":[\"type\",\"coordinates\"],\"title\":\"Polygon\",\"type\":\"object\"},\"Polygons\":{\"items\":{\"$ref\":\"#/definitions/Polygon\"},\"type\":\"array\"}},\"properties\":{\"areas\":{\"$ref\":\"#/definitions/Polygons\"},\"dict_output\":{\"$ref\":\"#/definitions/Metadata\"},\"geojson\":{\"description\":\"A Geojson.FeatureCollection containing only Polygons as geometries\",\"properties\":{\"features\":{\"items\":{\"$schema\":\"http://json-schema.org/draft-06/schema#\",\"properties\":{\"geometry\":{\"$ref\":\"#/definitions/Polygon\"},\"properties\":{\"oneOf\":[{\"type\":\"null\"},{\"type\":\"object\"}]},\"type\":{\"enum\":[\"Feature\"],\"type\":\"string\"}},\"required\":[\"type\",\"properties\",\"geometry\"],\"title\":\"GeoJSON Feature\",\"type\":\"object\"},\"type\":\"array\"},\"type\":{\"type\":\"string\"}},\"type\":\"object\"},\"image\":{\"$ref\":\"#/definitions/Image\"},\"image_list\":{\"$ref\":\"#/definitions/Images\"},\"integer_output\":{\"type\":\"integer\"},\"number_output\":{\"type\":\"number\"},\"string_output\":{\"type\":\"string\"}}},\"_links\":{\"self\":{\"relation\":\"Access to describe resource\",\"href\":\"http://localhost:4000/api/v1/describe\",\"type\":\"application/json\",\"method\":\"GET\"},\"execution\":{\"relation\":\"Processing resource\",\"href\":\"http://localhost:4000/api/v1/process\",\"type\":\"Complex type, see output in describe content for more information\",\"method\":\"POST\"},\"config\":{\"relation\":\"Processing configuration\",\"href\":\"http://localhost:4000/api/v1/config\",\"type\":\"application/json\",\"method\":\"GET\"},\"version\":{\"relation\":\"Processing version\",\"href\":\"http://localhost:4000/api/v1/version\",\"type\":\"application/json\",\"method\":\"GET\"},\"health\":{\"relation\":\"Processing health\",\"href\":\"http://localhost:4000/api/v1/health\",\"type\":\"text/plain\",\"method\":\"GET\"}}}\n</code></pre>"},{"location":"deploy_web_service.html#health","title":"health","text":"<p>It provides a simple health check of the deployed web service</p> <pre><code>curl http://localhost:4000/api/v1/health\n</code></pre> <p>Success</p> <p>Return <code>OK</code> if the service is up and running</p>"},{"location":"deploy_web_service.html#process","title":"process","text":"<p>It calls the processing function on provided input parameters. If asynchronous is false in the description, then the call blocks until the result is available. Otherwise, the function returns a jobid for later retrieval of the result -- process</p> <pre><code>curl -X POST \"http://localhost:4000/api/v1/process\" -d {process_payload}\n</code></pre>"},{"location":"deploy_web_service.html#jobs-list","title":"Jobs list","text":"<p>This endpoint returns the list of submitted job. It is available only if asynchronous is set to true in the description. </p> <pre><code>curl http://localhost:4000/api/v1/jobs\n</code></pre>"},{"location":"deploy_web_service.html#job-status-asynchronous","title":"Job status (asynchronous)","text":"<p>This endpoint returns the status of a submitted job. It is available only if asynchronous is set to true in the description. </p> <pre><code>curl http://localhost:4000/api/v1/jobs/{jobID}/status\n</code></pre>"},{"location":"deploy_web_service.html#job-result-asynchronous","title":"Job result (asynchronous)","text":"<p>This endpoint returns the result of a submitted job. It is available only if asynchronous is set to true in the description. </p> <pre><code>curl http://localhost:4000/api/v1/jobs/{jobID}/results\n</code></pre>"},{"location":"deploy_web_service.html#stateful-stateless-services","title":"Stateful &amp; Stateless services","text":"<p>PESTO supports building stateless services as well as stateful services.</p> <ul> <li> <p>Stateless: The service replies directly to the processing request with the response. These services should have no internal state and should always return the same result when presented with the same payload</p> </li> <li> <p>Stateful: The service can have internal states, and store the processing results to be later queried.</p> </li> </ul> <p>The main difference is that sending a processing request to <code>api/v1/process</code> to a stateful service will not return the result but a <code>jobID</code>. </p> <p>The job state can be queried at <code>GET api/v1/jobs/{jobID}/status</code> and results can be queried at  <code>GET api/v1/jobs/{jobID}/results</code> when the job is done.  The response of the latter request will be a json matching the output schema with URI to individual content (that should individually be queried using <code>GET requests</code>)</p> <p></p> <p>You can build the stateful service by using the profile tool with:</p> <pre><code>pesto build {PESTO_PROJECT_ROOT} -p stateful\n</code></pre> <p>Note</p> <p>In practice, it activates the <code>description.stateful.json</code> file (already in template) which set <code>asynchronous</code> at <code>True</code>: <pre><code>{\n    \"description\": \"My first deployment with PESTO, stateful version\",\n    \"asynchronous\": true\n}\n</code></pre></p> <p>And start the resulting stateful docker image: </p> <pre><code>docker run --rm -p 4000:8080 {project-name}:{project-version}-stateful\n</code></pre> <p>Then, run the API usage script (<code>python scripts/example_api_usage.py</code>) while having modified the image name to stateful:</p> StatefulStateless <pre><code>service = \"algo-service:1.0.0.dev0-stateful\"\n</code></pre> <pre><code>service = \"algo-service:1.0.0.dev0\"\n</code></pre> <p>This script should send several requests (like <code>pesto test</code>), but the advantage is that it doesn't kill the service afterwards, so it is possible to look at what happened:</p> <ul> <li>Try doing a get request on <code>/api/v1/jobs/</code> you should see a list of jobs</li> </ul> <pre><code>curl \"http://localhost:4000/api/v1/jobs/\"\n</code></pre> <ul> <li>Grab a job id then do a GET request on <code>/api/v1/jobs/{jobID}/status</code>. </li> </ul> <p><pre><code>curl \"http://localhost:4000/api/v1/jobs/{jobID}/status\"\n</code></pre> It should be \"DONE\"</p> <ul> <li>Then do a GET request on <code>/api/v1/jobs/{jobID}/results</code> to get results</li> </ul> <pre><code>curl \"http://localhost:4000/api/v1/jobs/{jobID}/results\"\n</code></pre> <p>It returns the result of the packaged algorithm</p>"},{"location":"details_conventions.html","title":"Conventions: using PESTO properly","text":""},{"location":"details_conventions.html#image-format-numpy-array","title":"Image format (numpy array)","text":"<p>For image processing solutions, PESTO offers mechanisms to indifferently feed algorithms with images as hyperlinks (either on a web server, on the disk, or in a GCP storage) or base64 encoded data as far as the Image type is used. For that purpose, raster.io is used.</p> <p>PESTO decodes input request in a specific way, which means that for images they are provided to the algorithm in Channel,Height,Width format,  PESTO is based on numpy arrays to send to or receive from the packaged algorithm. The convention is to encode images as arrays with 3 dimensions <code>(C,H,W)</code> :</p> <ul> <li>C is the channel number</li> <li>H is the lines number</li> <li>W is the columns number</li> </ul> <p>For example, an RGBA image of dimension 256x256 should be encoded as a numpy array of shape (4,256,256).</p> <p>Warning</p> <p>The usual format for images is <code>(H,W,C)</code>.  This means that a transposition is required to wrap them up in PIL format for example.</p> <p>Tip</p> <p>With <code>image</code> as a <code>np.array</code>, the easiest way to do so is to call <code>image = image.transpose((1, 2, 0))</code> to reorder bands</p>"},{"location":"details_conventions.html#delivery-name-convention","title":"Delivery name convention","text":"<p>Given a <code>build.json</code> file : <pre><code>{\n  \"name\": \"service-xxx\",\n  \"version\": \"a.b.c\"\n}\n</code></pre></p> <p>and the build command : <pre><code>pesto build build.json -p p1 p2\n</code></pre></p> <p>The packaged docker image is automatically named : <pre><code>service-xxx:a.b.c-p1-p2\n</code></pre></p>"},{"location":"details_conventions.html#docker-image-naming","title":"Docker image naming","text":"<p>Docker images naming convention is : </p> <ul> <li><code>{ service-name }:{version}</code> when no profile is used</li> <li><code>{ service-name }:{version}-stateful</code> when no profile is used and the service is asynchronous.</li> <li><code>{ service-name }:{version}-{profile}</code> when a profile is specified</li> <li><code>{ service-name }:{version}-{profile}-stateful</code> when a profile is specified and the service is asynchronous.</li> </ul>"},{"location":"details_conventions.html#pesto-internal-workspaces","title":"PESTO internal workspaces","text":"<p>Pesto uses workspaces for building services and storing partial responses in asynchronous mode. Finally, automatic testing copy resources (images) to a temporary folder. Here is a description of the paths where PESTO could write some files :</p> <pre><code>pesto-cli build :                           $HOME/.pesto/service-name/x.y.z/\npesto-cli build requirements (local cache): $HOME/.pesto/.processing-factory-requirements/\npesto-ws async jobs files :                 $HOME/.pesto/.processing/jobs/${job_id}/\npesto-template (unit testing) :             /tmp/pesto/test\n</code></pre>"},{"location":"details_cookbook.html","title":"PESTO Cookbook","text":""},{"location":"details_cookbook.html#how-to-load-resources-only-once-at-server-start-i-dont-want-to-reload-my-model-for-each-prediction","title":"How to load resources only once (at server start) : I don't want to reload my model for each prediction ?","text":"<p>Use static variables in Process class. Ex: <pre><code>class Process:\n    heavy_requirement = None\n\n    def process(self, *args, **kwargs):\n        # load only once\n        if Process.heavy_requirement is None:\n            Process.heavy_requirement = ...\n\n        # use heavy_requirement for processing\n        ... \n</code></pre></p>"},{"location":"details_cookbook.html#how-to-use-profiles-to-factorize-pesto-configurations","title":"How to use profiles to factorize PESTO configurations ?","text":"<p>Imagine you want to build two services out of one algorithm implementation :</p> <ul> <li>cpu : run on CPU with a specific model and requirements,</li> <li>gpu : run on GPU with another model and requirements.</li> </ul> <p>In 'pesto/build/' you can use three files to define requirements :</p> <ul> <li>requirements.json : common requirements,</li> <li>requirements.cpu.json : specific CPU requirements,</li> <li>requirements.gpu.json : specific GPU requirements.</li> </ul> <p>Then build your service with the '--profile' or '-p' option :</p> <pre><code>pesto build path/to/project -p cpu\npesto build path/to/project -p gpu\n</code></pre> <p>More details in the profile section of the PESTO documentation.</p>"},{"location":"details_cookbook.html#how-to-use-profiles-to-build-variants-of-a-same-algorithm","title":"How to use profiles to build variants of a same algorithm ?","text":"<p>For exemple you want to build your algorithm with 2 variants :</p> <ul> <li>raster : return detections as an image mask,</li> <li>vector : return detections as a geometry.</li> </ul> <p>Build your service with the '--profile' or '-p' option :</p> <pre><code>pesto build path/to/project -p raster cpu\npesto build path/to/project -p vector cpu\n</code></pre> <p>Use 'Pesto.is_profile_active(profile:str)' to check at runtime which profile was used during build.</p> <pre><code>from pesto.common.pesto import Pesto\nclass Process:\n    def process(self, *args, **kwargs):\n        mask_output = ...\n        if Pesto.is_profile_active('raster'):\n            return mask_output\n        if Pesto.is_profile_active('vector'):\n            return vectorize(mask_output)\n        raise NotImplementedError()\n</code></pre>"},{"location":"details_cookbook.html#how-to-install-include-files-in-the-docker-image","title":"How to install / include files in the docker image ?","text":"<p>Pesto will copy or pip install all your requirements in the output docker image.</p> <p>You just need to define all your service requirements in the 'pesto/build/requirements.json' file.</p>"},{"location":"details_cookbook.html#how-to-test-the-service-built-with-pesto","title":"How to test the service built with PESTO ?","text":"<p>Be sure to have a proper pesto-service python project (use the <code>pesto init</code> command). Then, go in your project <code>pesto/tests</code> directory and start editing files.</p> <p>The <code>pesto/tests</code> is composed of :</p> <ul> <li>some directories (one per processing to be run)</li> <li>a <code>expected_describe.json</code> file</li> </ul> <p>Each <code>pesto/tests/xxx</code> directory is composed  of :</p> <ul> <li>an <code>input</code> directory matching <code>pesto/api/input_schema.json</code>,</li> <li>an <code>output</code> directory matching <code>pesto/api/output_schema.json</code>.</li> </ul> <p>The <code>input</code> and <code>output</code> directories both describes a json payload (the processing input and output). Each filename <code>key.type</code> in those folders must match an entry in its corresponding <code>*_schema.json</code> :</p> <ul> <li><code>key</code> is the key in the <code>*_schema.json</code>,</li> <li><code>type</code> is the primitive type of the key :<ul> <li>string, float, int,</li> <li>json : dictionaries</li> <li>.tif, .jpg, *.png for images.</li> <li>arrays can be constructed using a folder <code>key</code> containing its enumerted items (<code>1.int</code>, <code>2.int</code>, ...)</li> </ul> </li> </ul> <p>Example</p> <p>The following describes the correspondence between the file structure and the json payload.</p> <ul> <li>pesto/tests/input<ul> <li>key1.string (containing <code>text</code>)</li> <li>key2.int (containing <code>33</code>)</li> <li>key3.float (containing <code>3.14</code>)</li> </ul> </li> </ul> <pre><code>{\n    \"key1\" : \"text\",\n    \"key2\" : 33,\n    \"key3\" : 3.14\n}\n</code></pre> <p>More examples are provided in the default pesto template.</p> <p>Then, it is required to build your project (once). <pre><code>pesto build /path/to/pesto-service -p p1 p2\n</code></pre></p> <p>Finally, run the tests : <pre><code>pesto test /path/to/pesto-service -p p1 p2\n</code></pre></p> <p>Note</p> <ul> <li>No code to write in the template-service</li> <li>Directly fill the directories at the root of <code>pesto/tests</code></li> <li>Run <code>pesto tests /path/to/pesto-service -p cpu</code> to test a built docker image with the selected profile.</li> </ul>"},{"location":"details_design.html","title":"Design presentation","text":""},{"location":"details_design.html#introduction","title":"Introduction","text":"<p>PESTO stands for ProcESsing facTOry and was initially designed to answer the need for fast and efficient integration of image processing algorithms using deep learning (DL) in our ground segment products.</p> <p>Next sections are organized as follows: </p> <ul> <li>Need identification: this section presents the expectations, what we would like to do.</li> <li>Base architecture identification: this section details the architecture of Pesto. It describes how we answer to our objectives.</li> <li>Implementation details: this section details some technologies used by pesto</li> <li>Processing API management: this section provides guidelines on how to design a processing API for PESTO.</li> <li>Performances: this section tells how PESTO should perform, how we demonstrated it was scalable.</li> </ul>"},{"location":"details_design.html#need-identification","title":"Need identification","text":"<p>The road from the design and development of a DL algorithm by data scientists to their integration in the image chain and finally the ground segment can be fastidious due to all the teams and all the required skills involved along the integration chain. Moreover, a DL solution, like cloud detection for instance, will usually be included in different products of our offer (like PNEO, DIGINEO or OneAtlas) having their own integration technologies, constraints and specificities. In addition, DL algorithms are frequently updated, either when the training dataset or the model is modified. Therefore, we can\u2019t afford to have an integration effort too long and complex, for each algorithm in each of our product.  </p> <p>It is then clear that standardizing key APIs, defining a common process and sharing common tools could greatly facilitate the delivery of DL algorithms and by extension of data processing algorithms, either delivered by our providers or designed by ourselves.</p> <p>From these remarks and an analysis of what should be PESTO, a base architecture is proposed in the next section.</p>"},{"location":"details_design.html#base-architecture-definition","title":"Base architecture definition","text":"<p>Let\u2019s take the widespread use case of cloud detection on satellite imagery in order to introduce the main integration steps and possibilities.  A classical workflow applied when images are received can be represented as follows:</p> <p></p> <p>Figure: Illustration of a cloud detection pipeline</p> <p>As we see, the cloud detection algorithm is integrated in a global image processing chain that will trigger many instances of it. Indeed, large scene images has to be split in smaller images that are compatible with the algorithm (RAM or GPU memory limit), and the processing needs to be distributed to provide high processing throughput and low latency. PESTO should then facilitate the integration of processing algorithms in various distributed processing frameworks used in our products. </p> <p>In the current illustration, the algorithm processes images as they are received, but it might also be on user request for on-demand processing or based on an event triggered by a monitoring function in other scenario. PESTO should then facilitate the reuse of processing algorithms by various orchestrators used in our products.</p> <p>The described pipeline does not detail the type and format of the data that is exchanged in between tasks. For image tiles, it could be a binary buffer containing the image itself or an URL pointing to a file to be fetched. Moreover, the information could be provided by different technologies (HTTP/REST, Apache KAFKA bus, SOAP,...). It will depend on the solution selected at the system level. But in any manner, the processing algorithm will need the image data. PESTO should then facilitate the definition of algorithms API and encourage the definition and use of common data types.</p> <p>And as it was mentioned several times, the processing algorithm needs to be deployed in many places. Therefore, PESTO should allow implementing the strategy develop and validate once, deploy everywhere.</p> <p>The base architecture of PESTO is then derived from these needs. PESTO is composed of a runtime proper to each processing function, a packaging manager to create PESTO runtimes tuned for each processing function and a testing framework.</p>"},{"location":"details_design.html#pesto-runtime","title":"PESTO runtime","text":"<p>The runtime is a webserver which conforms to an OpenAPI specification. The OpenAPI Specification (OAS) defines a standard, language-agnostic interface to RESTful APIs which allows both humans and computers to discover and understand the capabilities of the service without access to source code, documentation, or through network traffic inspection. When properly defined, a consumer can understand and interact with the remote service with a minimal amount of implementation logic, see SWAGGER.</p> <p>The architecture of the runtime is represented as follows:</p> <p></p> <p>Figure: Architecture of a PESTO runtime for cloud detection</p> <p>PESTO web server offers three web services that are :</p> <ul> <li>/api/v1/health: provides information on the availability of the service</li> <li>/api/v1/describe: provides information on the processing service that is deployed. Information on inputs, outputs, deployment requirements and so on are given here. PESTO does not constrain the definition of input and output parameters to offer a versatile solution. In return, a standardization effort has to be conducted in parallel.</li> <li>/api/v1/process: call the processing function. Request parameters must respect the definition provided by <code>/api/v1/describe</code>.</li> </ul> <p>PESTO is also in charge to convert, when required, the data from the REST API to the processing API. For most of parameters, they won\u2019t be any major conversion. In the current implementation, only the image type is converted such that the processing has access to the image data as a buffer. The philosophy is to remove any I/O operations from the algorithm implementation to limit the any adherence with the data source or destination.</p> <p>The runtime is provided as a standalone docker image that can be deployed everywhere and how many times as necessary.</p>"},{"location":"details_design.html#pesto-packaging-manager","title":"PESTO packaging manager","text":"<p>The packaging manager is a set of tools and templates to help the data scientist to deliver its algorithm.  Indeed, one goal of PESTO is really to ease the delivery of an algorithm designed by a data scientist.</p> <p>The packaging workflow is described as follows:</p> <p></p> <p>Figure: PESTO packaging workflow</p>"},{"location":"details_design.html#pesto-testing-framework","title":"PESTO testing framework","text":"<p>PESTO provides mechanisms to test the embedded processing function. A set of input and expected output parameters are provided by the data scientist.  Then, the test function deploys the PESTO runtime and run tests.</p>"},{"location":"details_design.html#implementation-details","title":"Implementation details","text":"<p>PESTO is developed with Python3. Indeed, many Deep Leaning tools and frameworks are provided in this language. Moreover, Python can easily use native code if necessary.</p> <p>FastAPI is used to implement the webserver. It offers async operations which allow to write non-blocking code.</p> <p>In order to make the link between requests on the web server and the processing implemented by the data scientist, a template to implement a python package and to provide a description of the API as well as build requirements is provided. </p> <p>The python package is named <code>algorithm.process.Process</code>. The data scientist needs to fill the signature and the content of the process function and in particular include the call to the implementation of the processing function.</p> <p>Then a set of configuration files have to be updated. A first set of configuration files (located in <code>pesto/api</code>) defines the API of the algorithm. Their content is described in the next section.</p> <p>A second set of configuration files (located in <code>pesto/build</code>) defines how to build the runtime.  We can define which root docker image to use, how to include DL models and parameters in the runtime, the name and version of the runtime... </p> <p>One additional feature is the possibility to define several independent runtime profiles. For example, it is useful to define a runtime using only CPUs and a runtime using the GPU. </p>"},{"location":"details_design.html#processing-api-management","title":"Processing API management","text":"<p>The PESTO runtime is designed to be extremely versatile by letting a full freedom on the definition of interfaces. The solution can then address many, if not all, use cases, which makes it its strength. </p> <p>PESTO does not guarantee the interoperability of processing functions which is also a key element in our ground segment solutions. Therefore, a complementary effort is conducted to standardize common data types in order to enforce interoperability.</p> <p>PESTO recommended philosophy is then to capitalize JSON Schema defining data types as well as functions used to convert from the REST API type to the algorithm type (like it is done for images).</p> <p>This effort has been conducted for Earth Observation data processing jointly with Airbus Defense and Space / Connected Intelligence teams. A common API, named geoprocessing-api, was then defined and can be found here.</p> <p>We provide here some guidelines to define and manage JSON Schema used to define API.</p> <ul> <li>Define common data types and rely on existing ones as much as possible to ease interoperability,</li> <li>Define data types that can be managed by higher level orchestrators: they need to known data types to provide the right information in the right format, possibly calling converters,</li> <li>Define API that will allow to chain processing function.</li> </ul> <p>The definition of processing API should then be organized as depicted as follows:</p> <p></p> <p>Figure: Processing API management</p> <ul> <li> <p>MyDescribe.yml:</p> <ul> <li> <p>Declares features of the process. It is used by orchestrators to select a service, deploy its docker image, feed it with the right data and exploit its result,</p> </li> <li> <p>The Format is extremely open to support any type of micro-service, however it is already batch processing compliant.</p> </li> </ul> </li> <li> <p>Default data types for GeoApplications:</p> <ul> <li> <p>image.json: Declares the format of an image and its attributes: compression type, spectral bands, sensor, ephemeris.</p> </li> <li> <p>imageCapabilities: Declares how to specify filters describing supported images.</p> </li> <li> <p>inputCapabilities: gather together all possible input capabilities of the project, somehow it references ImageCapabilities.json</p> </li> </ul> </li> </ul>"},{"location":"details_design.html#performances","title":"Performances","text":"<p>PESTO runtime is a wrapper around the algorithm to make it available as a web service. It transfers inputs and outputs from one side to the other. The intrinsic performances, i.e. performances related to the goal of the function like the detection rate for object detection, of the algorithm are not altered by PESTO. It can eventually add a little processing time or latency overhead, i.e. extrinsic performances. But PESTO should not affect them in a significative way as it simply passes REST API arguments to the algorithm. It should provide equivalent overhead on extrinsic performances as any web service implementation.</p> <p>The memory overhead, that also characterizes the extrinsic performances, has not been evaluated yet. But in our use cases involving image processing, it should remain negligible.</p> <p>Example: GCP deployment</p> <p>PESTO has been deployed at scale in Google Cloud Platform to process large satellite imagery.  The architecture of the deployed system is represented as follows: </p> <p></p> <p>Figure: PESTO at scale for EO processing with GPU</p> <p>PESTO runtimes are identified with the icon . </p> <p>The platform was created with 3 GPU workers and 13 workers (with 8 CPU each) for PESTO runtimes.</p> <p>Example: Conductor deployment</p> <ul> <li>PESTO has also been deployed at larger scale with Conductor (Orchestrator from Netflix) to run a pipeline of two tasks provided as PESTO micro services:</li> </ul> <p></p> <p>Figure: PESTO at scale with Conductor</p> <p>100 workers for PESTO were created.</p>"},{"location":"details_troubleshooting.html","title":"Troubleshooting","text":"<p>Here will be reported frequently encountered problems and tips to solve them.</p>"},{"location":"get_started.html","title":"Get started","text":"<p>Get started with PESTO ! Let's see how to package a simple processing algorithm.</p>"},{"location":"get_started.html#prerequisite","title":"Prerequisite","text":"<ul> <li>python &gt;= 3.6, &lt;= 3.9</li> <li>pip or git</li> <li>docker</li> </ul> <p>macOS</p> <p>For macOS users, it is necessary to set the <code>DOCKER_DEFAULT_PLATFORM</code> <pre><code>export DOCKER_DEFAULT_PLATFORM=linux/amd64\n</code></pre></p>"},{"location":"get_started.html#installation","title":"Installation","text":"<p>First, install PESTO-CLI in your environment as follows:</p> PypiFrom source <pre><code>$ pip install processing-factory\n</code></pre> <pre><code>$ git clone https://github.com/AirbusDefenceAndSpace/pesto.git\n$ cd pesto &amp;&amp; make install\n</code></pre> <p>Now check your installation.</p> <pre><code>$ pesto --help\n</code></pre> <pre><code>---------------------------------------------------------------------------------------------------------------------------\n  ____  _____ ____ _____ ___        ____                              _                 __            _\n |  _ \\| ____/ ___|_   _/ _ \\   _  |  _ \\ _ __ ___   ___ ___  ___ ___(_)_ __   __ _    / _| __ _  ___| |_ ___  _ __ _   _\n | |_) |  _| \\___ \\ | || | | | (_) | |_) | '__/ _ \\ / __/ _ \\/ __/ __| | '_ \\ / _` |  | |_ / _` |/ __| __/ _ \\| '__| | | |\n |  __/| |___ ___) || || |_| |  _  |  __/| | | (_) | (_|  __/\\__ \\__ \\ | | | | (_| |  |  _| (_| | (__| || (_) | |  | |_| |\n |_|   |_____|____/ |_| \\___/  (_) |_|   |_|  \\___/ \\___\\___||___/___/_|_| |_|\\__, |  |_|  \\__,_|\\___|\\__\\___/|_|   \\__, |\n                                                                              |___/                                 |___/\n-----  ProcESsing facTOry : 1.4.3     -------------------------------------------------------------------------------------\nUsage: pesto [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --install-completion [bash|zsh|fish|powershell|pwsh]\n                                  Install completion for the specified shell.\n  --show-completion [bash|zsh|fish|powershell|pwsh]\n                                  Show completion for the specified shell, to\n                                  copy it or customize the installation.\n  --help                          Show this message and exit.\n\nCommands:\n  build      Build docker image with Pesto from given build.json\n  init       Initialize a new algorithm in the given target directory\n  list       List projects in PESTO workspace\n  run        Run pesto processes\n  schemagen  Generate the input &amp; output schemas from input_output.py\n  test       Test algorithm from given build.json\n</code></pre> <p>PESTO is successfully installed</p>"},{"location":"get_started.html#create-pesto-project","title":"Create PESTO project","text":"<p>Create a directory to store your pesto project.</p> <p>Use the init command to create a new PESTO project to package your algorithm: </p> <pre><code>export MY_PESTO_DIR=/tmp/pesto\npesto init $MY_PESTO_DIR\n</code></pre> <p>In prompt, you can edit descriptors of the project (see init) or press enter to keep the defaults values.</p> <pre><code>---------------------------------------------------------------------------------------------------------------------------\n  ____  _____ ____ _____ ___        ____                              _                 __            _\n |  _ \\| ____/ ___|_   _/ _ \\   _  |  _ \\ _ __ ___   ___ ___  ___ ___(_)_ __   __ _    / _| __ _  ___| |_ ___  _ __ _   _\n | |_) |  _| \\___ \\ | || | | | (_) | |_) | '__/ _ \\ / __/ _ \\/ __/ __| | '_ \\ / _` |  | |_ / _` |/ __| __/ _ \\| '__| | | |\n |  __/| |___ ___) || || |_| |  _  |  __/| | | (_) | (_|  __/\\__ \\__ \\ | | | | (_| |  |  _| (_| | (__| || (_) | |  | |_| |\n |_|   |_____|____/ |_| \\___/  (_) |_|   |_|  \\___/ \\___\\___||___/___/_|_| |_|\\__, |  |_|  \\__,_|\\___|\\__\\___/|_|   \\__, |\n                                                                              |___/                                 |___/\n-----  ProcESsing facTOry : 1.4.3     -------------------------------------------------------------------------------------\n\nPlease fill necessary information to initialize your template\n\nmaintainer_fullname [pesto]: \nmaintainer_email [pesto@airbus.com]: \nproject_name [algo-service]: \nproject_sname [algo-service]: \nproject_short_description [Pesto Template contains all the boilerplate you need to create a processing-factory project]: \nproject_version [1.0.0.dev0]: \n\nService generated at /tmp/pesto/algo-service\n</code></pre> <p>Note</p> <p>The created PESTO Project <code>algo-service</code> is created from template and ready to use with a simple processing.  See init for more details on how to tune it for your needs.</p>"},{"location":"get_started.html#build-project-docker-image","title":"Build project docker image","text":"<p>Create the project docker image containing the default processing web service with pesto build function:</p> <pre><code>$ pesto build $MY_PESTO_DIR/algo-service\n</code></pre> <p>All the template requirements and algorithm configuration are used to create the docker image.  See configuration to adapt the template to your own algorithm. </p> <pre><code>---------------------------------------------------------------------------------------------------------------------------\n  ____  _____ ____ _____ ___        ____                              _                 __            _\n |  _ \\| ____/ ___|_   _/ _ \\   _  |  _ \\ _ __ ___   ___ ___  ___ ___(_)_ __   __ _    / _| __ _  ___| |_ ___  _ __ _   _\n | |_) |  _| \\___ \\ | || | | | (_) | |_) | '__/ _ \\ / __/ _ \\/ __/ __| | '_ \\ / _` |  | |_ / _` |/ __| __/ _ \\| '__| | | |\n |  __/| |___ ___) || || |_| |  _  |  __/| | | (_) | (_|  __/\\__ \\__ \\ | | | | (_| |  |  _| (_| | (__| || (_) | |  | |_| |\n |_|   |_____|____/ |_| \\___/  (_) |_|   |_|  \\___/ \\___\\___||___/___/_|_| |_|\\__, |  |_|  \\__,_|\\___|\\__\\___/|_|   \\__, |\n                                                                              |___/                                 |___/\n-----  ProcESsing facTOry : 1.4.3     -------------------------------------------------------------------------------------\n\n[...]\n\n=&gt; =&gt; naming to docker.io/library/algo-service:1.0.0.dev0  \n</code></pre> <p>The docker image <code>algo-service:1.0.0.dev0</code> is now available.</p>"},{"location":"get_started.html#test-the-docker-image","title":"Test the docker image","text":"<p>The template algorithm is an image classifier. The <code>algo-service</code> PESTO project contains an image to test the algorithm.</p> <p></p> <p>You can use this image to call the built docker image:</p> <pre><code>$ pesto run docker '{\"image\":\"file:///opt/algo-service/pesto/tests/resources/test_1/input/image.png\"}' algo-service:1.0.0.dev0 /tmp/output_pesto.json\n</code></pre> <p>It runs the built docker image, get the algorithm prediction on the image and stop the docker container.</p> <pre><code>---------------------------------------------------------------------------------------------------------------------------\n  ____  _____ ____ _____ ___        ____                              _                 __            _\n |  _ \\| ____/ ___|_   _/ _ \\   _  |  _ \\ _ __ ___   ___ ___  ___ ___(_)_ __   __ _    / _| __ _  ___| |_ ___  _ __ _   _\n | |_) |  _| \\___ \\ | || | | | (_) | |_) | '__/ _ \\ / __/ _ \\/ __/ __| | '_ \\ / _` |  | |_ / _` |/ __| __/ _ \\| '__| | | |\n |  __/| |___ ___) || || |_| |  _  |  __/| | | (_) | (_|  __/\\__ \\__ \\ | | | | (_| |  |  _| (_| | (__| || (_) | |  | |_| |\n |_|   |_____|____/ |_| \\___/  (_) |_|   |_|  \\___/ \\___\\___||___/___/_|_| |_|\\__, |  |_|  \\__,_|\\___|\\__\\___/|_|   \\__, |\n                                                                              |___/                                 |___/\n-----  ProcESsing facTOry : 1.4.3     -------------------------------------------------------------------------------------\n2022-12-14 04:52:36.311 | INFO     | pesto.common.testing.service_manager:run:92 - Starting container with algo-service:1.0.0.dev0 on port 4000\n2022-12-14 04:52:41.224 | INFO     | pesto.common.testing.service_manager:run:106 - Container f3cdc9911d3b2278baae0bcd87e8931a4641630d0d5a9d6076cc2b1b2e896e32 started, available at http://localhost:4000\n2022-12-14 04:52:41.226 | INFO     | pesto.common.testing.service_manager:run:112 - Trying api/v1/health for 1st time\n2022-12-14 04:52:41.398 | INFO     | pesto.common.testing.service_manager:run:114 - Server not yet alive\n2022-12-14 04:52:43.399 | INFO     | pesto.common.testing.service_manager:run:117 - Trying api/v1/health for 2th time\n2022-12-14 04:52:43.451 | INFO     | pesto.common.testing.service_manager:run:120 - Server alive\n2022-12-14 04:52:43.502 | DEBUG    | pesto.common.testing.endpoint_manager:process:44 - {\n  \"image\": \"file:///opt/algo-service/pesto/tests/resources/test_1/input/image.png\"\n}\n2022-12-14 04:52:49.380 | DEBUG    | pesto.common.testing.endpoint_manager:process:63 - {\n  \"image\": \"iVBORw0KGgoAAAANSUhEUgAAAcMAAAEsCAIAAAAw9k/eAAAgAElEQVR4nGS8WXIkSZIkyiKiqrb4gi32...\",\n\n[ ... ]\n\n        \"properties\": {\n          \"category\": \"egyptian_cat\",\n          \"confidence\": 0.42\n        },\n        \"type\": \"Feature\"\n      }\n    ]\n  }\n}\n2022-12-14 04:52:49.392 | INFO     | pesto.common.testing.service_manager:stop:132 - Stopping container f3cdc9911d3b2278baae0bcd87e8931a4641630d0d5a9d6076cc2b1b2e896e32\n</code></pre> <p>The image is labelled as <code>egyptian_cat</code> with a confidence of <code>0.42</code>.</p> <p>The algorithm is successfully packaged as a docker image</p>"},{"location":"package_configuration.html","title":"Configuring the PESTO packaging of your algorithm","text":"<p>Once you initialized the new PESTO project, a number of files has to be edited to describe the algorithm's input, output and requirements.</p> List of configuration files File Description <code>algorithm/process.py</code> The python file containing your algorithm with the <code>Process.process()</code> function <code>algorithm/input_output.py</code> The python file containing the input and output dataclasses <code>pesto/api/config.json</code> A generic configuration file at the disposal of <code>process.py</code> for its own configuration <code>pesto/api/config_schema.json</code> The schema of is a json schema file that specifies what config.json should look like <code>pesto/api/description.json</code> Description your processing algorithm <code>pesto/api/input_schema.json</code> Specifications of the algorithm's input format <code>pesto/api/output_schema.json</code> Specifications of the algorithm's output format <code>pesto/api/version.json</code> Algorithm version description <p>To package your algorithm with PESTO, you'll need to :</p> <ol> <li> <p>Provide the implementation of your algorithm within the <code>process()</code> function in <code>algorithm/process.py</code></p> </li> <li> <p>Specify the API of your algorithm, in other words its input and output formats in <code>pesto/api/input_schema.json</code> and <code>pesto/api/output_schema.json</code>. </p> </li> <li> <p>Describe and configure the dependencies in <code>pesto/api/description.json</code> and <code>pesto/build/requirements.json</code></p> </li> </ol> <p>Tip</p> <p>Always start from the pesto-template as it is already a working PESTO project.</p> <p>One of the main points of attention is to align schemas of <code>input_schema.json</code> and <code>output_schema.json</code> with the signature of the <code>process</code> function. Defining the input/output schemas can be done in two different ways:</p> <ul> <li> <p>either the <code>process()</code> function takes an <code>Input</code> object and returns an <code>Output</code> object specified in <code>input_ouput.py</code> : in that case, <code>pesto schemagen</code> can generate the schemas for you. This is the easiest and recommended way.</p> </li> <li> <p>or the <code>process()</code> function takes a set of parameters of your choice and returns an object : in that cas you have to specify by yourself the <code>input_schema.json</code> and <code>output_schema.json</code> contents. This is recommended for complex input/output structures that require a json schema that can not be inferred by <code>pesto schemagen</code>.</p> </li> </ul>"},{"location":"package_configuration.html#python-algorithm","title":"Python algorithm","text":"<p>Look at <code>algorithm/process.py</code>. This is the module that will be loaded by PESTO inside our server and which will be called during preprocessing. </p> <p>There is a <code>Process</code> class with <code>on_start()</code> and <code>process()</code> methods.</p>"},{"location":"package_configuration.html#processon_start","title":"Process.on_start()","text":"<p>The <code>algorithm/process.py</code> should contains a <code>Process</code> class with the <code>Process.on_start()</code> method.</p> <p>The <code>on_start()</code> method will be called on the first processing request. It is used to load resources such as Machine Learning models that are then called in the <code>Process.process()</code> method.</p>"},{"location":"package_configuration.html#processprocess","title":"Process.process()","text":"<p>The <code>algorithm/process.py</code> should contains a <code>Process</code> class with the <code>Process.process()</code> method.</p> <p>The <code>process()</code> method is called during call to <code>/api/v1/process</code>, when we want to actually process input data</p> <p>Warning</p> <p>Depending on the <code>Process.process()</code> function signature, you will be able to automatically generate or not the input/output schemas with <code>pesto schemagen</code>.</p> <p>If you can encapsulate the input parameters in the <code>algorithm.input_output.Input</code> dataclass and the returned objects in the <code>algorithm.input_output.Output</code> dataclass, then you can benefit from the schema generation. Simply edit the <code>algorithm/input_output.py</code> file to specify the input parameters and the output structure. The signature of the algorithm must be <pre><code>process(input: Input) -&gt; Output\n</code></pre></p> <p>If your algorithm <code>Process.process()</code> function takes a list of parameters or returns an object that is not an <code>Output</code>, then the signature is not compatible with  <code>pesto schemagen</code> : you will have to implement the schemas.</p> <p>process.py schemagen compatible, or not</p> Compatible with schemagenManual <p>process.py<pre><code>class Process(object):\n    def process(input: Input) -&gt; Output:\n        # do some processing on the input and return the result\n        return new Output({},{},1.0)\n</code></pre> input_output.py<pre><code>@dataclass\nclass Input:\n    image:np.array = definition(Definition.Image, required=True, description=\"Input image\")\n    dict_parameter:dict = definition(Definition.Metadata, description=\"A dict parameter\")\n\n@dataclass\nclass Output:\n    partial_result_1: dict = definition(Definition.Metadata)\n    partial_result_2: dict = definition(Definition.Metadata)\n    integer_output: int = field(\"Confidence value\")\n</code></pre></p> process.py<pre><code>class Process(object):\n    def process(self, image, dict_parameter) -&gt; dict:\n        # do some processing on the input and return the result\n        return {\n            'partial_result_1': {},\n            'partial_result_2': {},\n            'confidence': 1.0\n        }\n</code></pre> <p>Warning</p> <p>In this case, you also have to define manually the input/output schemas. This is detailed in the next section.</p> <p>Info</p> <p>Images are converted to/from numpy arrays by PESTO. Thus, the <code>Process.process()</code> function should expect to receive numpy arrays and always return images as numpy arrays.</p>"},{"location":"package_configuration.html#input-output-specification","title":"Input / Output specification","text":"<p>To run, PESTO needs the input and output schema files:</p> <ul> <li> <p><code>pesto/api/input_schema.json</code></p> </li> <li> <p><code>pesto/api/output_schema.json</code></p> </li> </ul>"},{"location":"package_configuration.html#with-schemagen","title":"With schemagen","text":"<p>If the <code>Process.process()</code> function takes an <code>Input</code> and returns an <code>Output</code>, then you can generate the <code>input_schema.json</code> and <code>output_schema.json</code>:</p> <pre><code>pesto schemagen --force algo-service/\n</code></pre> <p>Success</p> <pre><code>  [2022-12-21 13:50:33,830] 82809-INFO schemagen::__class2schema():l59:\n  Using the geojson user defined definition from PestoFiles.user_definitions_schema\n  [2022-12-21 13:50:33,830] 82809-INFO schemagen::__generate():l32:\n  The Input schema is now in algo-service/pesto/api/input_schema.json\n  [2022-12-21 13:50:33,831] 82809-INFO schemagen::__class2schema():l59:\n  Using the geojson user defined definition from PestoFiles.user_definitions_schema\n  [2022-12-21 13:50:33,832] 82809-INFO schemagen::__generate():l32:\n  The Output schema is now in algo-service/pesto/api/output_schema.json\n</code></pre> <p>See the documentation of <code>pesto schemagen</code> to see all the supported types.</p>"},{"location":"package_configuration.html#manually","title":"Manually","text":"<p>If you do/can not use <code>pesto schemagen</code>, then you have to define the processing input and output. The REST API use json to communicate with external services or users. We then use JSON schema to validate input payloads. </p> <p><code>pesto/api/input_schema.json</code> : specify the input validation schema</p> <p>Example: input_schema.json</p> <pre><code>{\n  \"image\": {\n    \"$ref\": \"#/definitions/Image\",\n    \"description\": \"Input image\"\n  },\n  \"dict_parameter\": {\n    \"$ref\": \"#/definitions/Metadata\",\n    \"description\": \"A dict parameter\"\n  },\n  \"object_parameter\": {\n    \"description\": \"A dict parameter with more spec, of the form {'key':'value'}\",\n    \"type\": \"object\",\n    \"properties\": {\n      \"key\": {\n        \"type\": \"string\"\n      }\n    }\n  },\n  \"number_parameter\": {\n    \"type\": \"number\",\n    \"description\": \"A (floating point) number parameter\"\n  },\n  \"integer_parameter\": {\n    \"type\": \"integer\",\n    \"description\": \"A (integer) number parameter\"\n  },\n  \"string_parameter\": {\n    \"type\": \"string\",\n    \"description\": \"A string parameter\"\n  },\n  \"required\": [\n    \"image\"\n  ]\n}\n</code></pre> <p><code>pesto/api/output_schema.json</code> : specify the output validation schema.</p> <p>Example: output_schema.json</p> <pre><code>{\n  \"image\": {\n    \"$ref\": \"#/definitions/Image\"\n  },\n  \"areas\": {\n    \"$ref\": \"#/definitions/Polygons\"\n  },\n  \"number_output\": {\n    \"type\": \"number\"\n  },\n  \"integer_output\": {\n    \"type\": \"integer\"\n  },\n  \"dict_output\": {\n    \"$ref\": \"#/definitions/Metadata\"\n  },\n  \"string_output\": {\n    \"type\": \"string\"\n  },\n  \"image_list\": {\n    \"$ref\": \"#/definitions/Images\"\n  },\n  \"geojson\": {\n    \"description\": \"A Geojson.FeatureCollection containing only Polygons as geometries\",\n    \"type\": \"object\",\n    \"properties\": {\n      \"features\": {\n        \"type\": \"array\",\n        \"items\": {\n          \"$schema\": \"http://json-schema.org/draft-06/schema#\",\n          \"title\": \"GeoJSON Feature\",\n          \"type\": \"object\",\n          \"required\": [\n            \"type\",\n            \"properties\",\n            \"geometry\"\n          ],\n          \"properties\": {\n            \"type\": {\n              \"type\": \"string\",\n              \"enum\": [\n                \"Feature\"\n              ]\n            },\n            \"properties\": {\n              \"oneOf\": [\n                {\n                  \"type\": \"null\"\n                },\n                {\n                  \"type\": \"object\"\n                }\n              ]\n            },\n            \"geometry\": {\n              \"$ref\": \"#/definitions/Polygon\"\n            }\n          }\n        }\n      },\n      \"type\": {\n        \"type\": \"string\"\n      }\n    }\n  }\n}\n</code></pre> <p>The <code>json</code> files contain the input/output variables name and their information (<code>type</code>/<code>$ref</code>, <code>description</code>)</p> <p>Default PESTO types can be found in the source code : <code>processing-factory/pesto-cli/pesto/cli/resources/schema/definitions.json</code></p>"},{"location":"package_configuration.html#requirements","title":"Requirements","text":"<p>PESTO provides a generic way to include any files in the final docker image using the <code>pesto/build/requirements.json</code> file.</p> <p>The following fields are required :</p> <ul> <li>environments: some user defined variables</li> <li>requirements: A (from,to) list, where <code>from</code> is an URI to some files and <code>to</code> is the target path in the docker image</li> <li>dockerBaseImage : the docker image to use as a base</li> </ul> <p>Example: requirements.json</p> <pre><code>{\n  \"environments\": {\n    \"DEEPWORK\": \"/deep/deliveries\",\n    \"DEEPDELIVERY\": \"/deep/deliveries\"\n  },\n  \"requirements\": {\n    \"lib1\": {\n      \"from\": \"file:///tmp/my-lib1\",\n      \"to\": \"/opt/lib1\",\n      \"type\": \"python\"\n    },\n    \"lib2\": {\n      \"from\": \"file:///tmp/my-lib2.tar.gz\",\n      \"to\": \"/opt/lib2\",\n      \"type\": \"pip\"\n    },\n    \"model\": {\n      \"from\": \"gs://path/to/my-model.tar.gz\",\n      \"to\": \"/opt/model\"\n    }\n  },\n  \"dockerBaseImage\": \"python:3.8-buster\"\n}\n</code></pre> <p>PESTO can handle requirements in many formats. Each requirement accepts an optional <code>type</code> field :</p> <ul> <li>python : add the <code>to</code> path to the PYTHONPATH environment variable</li> <li>pip : run a <code>pip install</code> command on the provided <code>wheel</code> or setuptools compatible <code>tar.gz</code> archive</li> <li>default : simply copy the files (uncompressed the <code>tar.gz</code> archive)</li> </ul> <p>Warning</p> <p>The tar.gz with type 'python' usage is DEPRECATED and will fail with an archive build with setuptools. Such an archive contains a root folder that should be removed when adding the path to PYTHON_PATH.</p>"},{"location":"package_docker_image.html","title":"Build the Docker image","text":""},{"location":"package_docker_image.html#create-docker-image","title":"Create docker image","text":"<p>When your project is properly configured (cf. project configuration), PESTO can build a docker image containing a running web service.</p> <p>If your project path is <code>PESTO_PROJECT_ROOT = /path/to/your/workspace/xxx-service</code> you can build it using :</p> <pre><code>pesto build {PESTO_PROJECT_ROOT}\n</code></pre> <p>It creates a packaged docker image:</p> <p>xxx-service:1.0.0.dev0</p>"},{"location":"package_docker_image.html#pesto-profiles-advanced","title":"PESTO Profiles (Advanced)","text":"<p>In order to accommodate for different hardware targets or slight variations of the same process to deploy, PESTO has a built-in capabilities called <code>profiles</code>.</p> <p>Basically, PESTO profiles is a  list of ordered strings (ex: <code>gpu</code>, <code>stateless</code>) whose .json files in <code>build/api</code> folders sequentially update the base file.</p> <p>To use them, simply add the list of profiles to your PESTO commands: </p> <pre><code>pesto build {PESTO_PROJECT_ROOT} -p gpu stateless\n</code></pre> <p>It creates a new packaged docker image specific to the profiles:</p> <p>xxx-service:1.0.0.dev0-stateful-gpu</p> <p>The details of profiles usage are explained in pesto build section.</p>"},{"location":"package_docker_image.html#adding-a-gpu-profile","title":"Adding a GPU profile","text":"<p>In order to create an image with GPU support, we can complete the proposed profile <code>gpu</code>. The file <code>requirements.gpu.json</code> can be updated as follows (ex: gpu compliant pytorch image):</p> <pre><code>{\n  \"environments\": {},\n  \"requirements\": {},\n  \"dockerBaseImage\": \"pytorch/pytorch:1.5-cuda10.1-cudnn7-runtime\"\n}\n</code></pre> <p>You can now build your GPU enabled microservice :</p> <pre><code>pesto build {PESTO_PROJECT_ROOT} -p gpu\n</code></pre> <p>It creates a new packaged docker image of the algorithm able to run on GPU:</p> <p>xxx-service:1.0.0.dev0-gpu</p> <p>Nvidia drivers</p> <p>If you have a computer with nvidia drivers &amp; a gpu you can try to run <pre><code>pesto build {PESTO_PROJECT_ROOT} -p gpu\npesto test {PESTO_PROJECT_ROOT} -p gpu --nvidia\n</code></pre> It should do the same as above but with gpu support (and actually run the process on gpu).</p>"},{"location":"package_docker_image.html#multiple-algorithm-versions","title":"Multiple algorithm versions","text":"<p>The algorithm process is implemented in the <code>algorithm/process.py</code> with the <code>Process</code> class (see configuration).</p> <p>If multiple version of an algorithm must be maintained, it is advised to :</p> <ul> <li>Create multiple python implementation of the <code>Process</code> class (one per file)</li> <li>In the main <code>algorithm/process.py</code>, select the proper implementation of <code>Process</code> to import</li> </ul> <p>The following is an example using pesto profiles to switch from one algorithm to another at build time.</p> <p>process.py schemagen compatible, or not</p> <p>Create <code>algorithm/process_v1.py</code>, <code>algorithm/process_v2.py</code>, <code>algorithm/process_v3.py</code>, each with it own implementation of the <code>Process</code> class.</p> <p>Use the <code>pesto.common.pesto.Pesto.is_profile_active()</code> to check the current profile (see check profile).</p> algorithm/process.py<pre><code>from pesto.common.pesto import Pesto\n\nif Pesto.is_profile_active('v1'):\n    from algorithm import process_v1\n    Process = process_v1.Process\nelif Pesto.is_profile_active('v2'):\n    from algorithm import process_v2\n    Process = process_v2.Process\nelse:\n    from algorithm import process_v3\n    Process = process_v3.Process\n</code></pre> <p>At the build time, it is possible to build one docker image per algorithm version:</p> <pre><code>pesto build {PESTO_PROJECT_ROOT} -p v1\npesto build {PESTO_PROJECT_ROOT} -p v2\n</code></pre> <p>It creates the two packaged docker images of the algorithm versions:</p> <pre><code>xxx-service:1.0.0.dev0-v1\nxxx-service:1.0.0.dev0-v2\n</code></pre>"},{"location":"package_pesto_project.html","title":"Create PESTO project","text":"<p>The first step to package your processing library is to create a new project.</p> <p>In a terminal, use the pesto init command to create a PESTO project in the desired repository. :</p> <pre><code>pesto init /path/to/your/workspace\n</code></pre> <p>You will be prompted for some information to fill the default template:</p> <pre><code>---------------------------------------------------------------------------------------------------------------------------\n  ____  _____ ____ _____ ___        ____                              _                 __            _\n |  _ \\| ____/ ___|_   _/ _ \\   _  |  _ \\ _ __ ___   ___ ___  ___ ___(_)_ __   __ _    / _| __ _  ___| |_ ___  _ __ _   _\n | |_) |  _| \\___ \\ | || | | | (_) | |_) | '__/ _ \\ / __/ _ \\/ __/ __| | '_ \\ / _` |  | |_ / _` |/ __| __/ _ \\| '__| | | |\n |  __/| |___ ___) || || |_| |  _  |  __/| | | (_) | (_|  __/\\__ \\__ \\ | | | | (_| |  |  _| (_| | (__| || (_) | |  | |_| |\n |_|   |_____|____/ |_| \\___/  (_) |_|   |_|  \\___/ \\___\\___||___/___/_|_| |_|\\__, |  |_|  \\__,_|\\___|\\__\\___/|_|   \\__, |\n                                                                              |___/                                 |___/\n-----  ProcESsing facTOry : 1.4.3     -------------------------------------------------------------------------------------\n\nPlease fill necessary information to initialize your template\n\nmaintainer_fullname [pesto]: \nmaintainer_email [pesto@airbus.com]: \nproject_name [algo-service]: \nproject_sname [algo-service]: \nproject_short_description [Pesto Template contains all the boilerplate you need to create a processing-factory project]: \nproject_version [1.0.0.dev0]: \n\nService generated at /path/to/your/workspace/algo-service\n</code></pre> <p>You can press ENTER to let the default values of the project description fields.</p> <p>This will create a new project named <code>/path/to/your/workspace/xxx-service</code> with the following structure:</p> <pre><code>algo-service/\n\u251c\u2500\u2500 ...\n\u251c\u2500\u2500 Makefile\n\u251c\u2500\u2500 algorithm\n\u2502   \u251c\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 input_output.py\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 process.py\n\u251c\u2500\u2500 pesto\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 api\n\u2502   \u2502   \u251c\u2500\u2500 ...\n\u2502   \u2502   \u251c\u2500\u2500 description.json\n\u2502   \u2502   \u251c\u2500\u2500 description.stateful.json\n\u2502   \u2502   \u251c\u2500\u2500 input_schema.json\n\u2502   \u2502   \u251c\u2500\u2500 output_schema.json\n\u2502   \u2502   \u2514\u2500\u2500 user_definitions.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 build\n\u2502   \u2502   \u251c\u2500\u2500 build.json\n\u2502   \u2502   \u251c\u2500\u2500 requirements.gpu.json\n\u2502   \u2502   \u2514\u2500\u2500 requirements.json\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 tests\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 ...\n</code></pre> <p>Note</p> <p>The project is ready and setup for a simple processing, but you should at least edit some configuration files to tune PESTO to your needs.</p>"},{"location":"package_test.html","title":"Test the Docker image","text":"<p>Now we want to test if everything goes well, which means:</p> <ul> <li>Launching the docker container and checking that it responds to http requests</li> <li>Checking that the process we just deployed is working correctly</li> </ul> <p>Fortunately, PESTO features a test/usage framework which is the purpose of the <code>pesto/test</code> folder</p>"},{"location":"package_test.html#booting-up-the-container-first-http-requests","title":"Booting up the container &amp; first http requests","text":"<p>If the build succeeds you should be able to see your image with</p> <pre><code>docker image ls\n</code></pre> <pre><code>REPOSITORY                                                  TAG          IMAGE ID       CREATED         SIZE\nalgo-service                                                1.0.0.dev0   f04d96bb57f4   4 minutes ago   1.16GB\n</code></pre> <p>First, we can verify that we are able to start the container and send very basic requests to it</p> <pre><code>docker run --rm -p 4000:8080 algo-service:1.0.0.dev0\n</code></pre> <p>This should start the container so that it can be accessed from <code>http://localhost:4000</code>.</p> <p>In your browser (or using CURL) you can send basic GET requests to your container:</p> <p>Health</p> <p><pre><code>CURL -X GET http://localhost:4000/api/v1/health\n</code></pre> It should answer <code>OK</code></p> <p>Describe</p> <p><pre><code>CURL -X GET http://localhost:4000/api/v1/describe\n</code></pre> It should return a json file</p>"},{"location":"package_test.html#using-pesto-test-command","title":"Using <code>pesto test</code> command","text":"<p>The first way of testing your service is to call <code>pesto test</code> utility the same way you called <code>pesto build</code>. In order, this command will:</p> <ul> <li>Run the docker container (the same way we did previously)</li> <li>Send requests to <code>api/v1/describe</code> and compare with the <code>expected_describe.json</code></li> <li>Send process payloads to <code>api/v1/process</code> and compare them to the desired outputs</li> </ul> <p>The inputs and desired output have to be configured in the test resources directory</p>"},{"location":"package_test.html#defining-test-resources","title":"Defining Test Resources","text":"<p>Let's take a look at the <code>pesto/test</code> directory</p> <pre><code>tests\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 resources/\n \u00a0\u00a0 \u251c\u2500\u2500 expected_describe.json\n \u00a0\u00a0 \u251c\u2500\u2500 test_1/\n \u00a0\u00a0 \u2514\u2500\u2500 test_2/\n</code></pre> <p>The <code>resources</code> folder will be used by the PESTO Test API and be converted to processing requests that will be sent to <code>/api/v1/process</code> with the right format. The response will then be compared to the expected response, and act as unit tests. </p> <p>The first file of interest is the <code>expected_describe.json</code>. This file will be compared to the <code>http://localhost:4000/api/v1/describe</code> json document returned by the API. This description file can be used to parse the information about the API (input / output schema, description etc...)</p> <p>You will learn in time how to manually create an <code>expected_describe.json</code> from the <code>pesto/api</code> folder, for now it is best to copy the <code>describe.json</code> file that we generated earlier and to put it as <code>expected_describe.json</code>. You can compare this file to the default <code>expected_describe.json</code> and notice how the differences translate themselves to the default processing</p> <p>Now, there are several folders named <code>test_*</code>. The purpose of these test folders is that the input payload files are deposited in <code>input</code> and the expected response is in <code>output</code></p> <p>Let's take a look at the test folder:</p> <pre><code>test_1\n\u251c\u2500\u2500 input\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dict_parameter.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 image.png\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 integer_parameter.int\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 number_parameter.float\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 object_parameter.json\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 string_parameter.string\n\u2514\u2500\u2500 output\n    \u251c\u2500\u2500 areas\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 0.json\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 1.json\n    \u251c\u2500\u2500 dict_output.json\n    \u251c\u2500\u2500 geojson.json\n    \u251c\u2500\u2500 image_list\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 0.png\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 1.png\n    \u251c\u2500\u2500 image.png\n    \u251c\u2500\u2500 integer_output.integer\n    \u251c\u2500\u2500 number_output.float\n    \u2514\u2500\u2500 string_output.string\n</code></pre> <p>You can see that both input and output have files with extension corresponding to input types (see pesto test). The filenames are matched with the json payload keys.</p>"},{"location":"package_test.html#run-pesto-test","title":"Run pesto test","text":"<p>To run the test on configured input/output, use the pesto test command:</p> <pre><code>pesto test {PESTO_PROJECT_ROOT}\n</code></pre> <p>The logs should show different steps being processed.</p> <p>You can check the responses and differences between dictionaries in the .pesto workspace: <code>/home/$USER/.pesto/tests/xxx-service/1.0.0.dev0</code></p> <p>You will find there the results / responses of all the requests, including describes and processing requests. This is a useful folder to debug potential differences.</p> <p>results.json</p> <p>Should everything goes well, the <code>results.json</code> file should look like this</p> <pre><code>{\n  \"describe\": {\n    \"NoDifference\": true\n  },\n  \"test_1\": {\n    \"NoDifference\": true\n  },\n  \"test_2\": {\n    \"NoDifference\": true\n  }\n}\n</code></pre>"},{"location":"package_test.html#bonus-using-pytest-unit-testing","title":"Bonus: Using Pytest &amp; unit testing","text":"<p>Once you're sure and have debugged properly you can write or edit unit tests in <code>{PESTO_PROJECT_ROOT}/tests/</code> (check the autogenerated file <code>tests/test_service.py</code> ) and run it with <code>pytest tests</code> on your root project</p> <p>This can be used to ensure non regression on further edits or if you want to do test driver development</p>"},{"location":"package_test.html#bonus-using-pesto-python-api-to-run-tests-send-requests-to-model","title":"Bonus: Using PESTO Python API to run tests &amp; send requests to model","text":"<p>Should you want to use in a non-scalable way or further test your services, you can have a look at the <code>{PESTO_PROJECT_ROOT}/scripts/example_api_usage.py</code> file that exposes the low level python API that is used in <code>pesto test</code></p> <ul> <li>The <code>ServiceManager</code> class is the class used as a proxy for the python Docker API, and is used to pull / run /attach / stop the containers</li> <li>The <code>PayloadGenerator</code> class is used to translate files to actual json payload for the REST API</li> <li>The <code>EndpointManager</code> manages the various endpoints of the processes, and act as a front to post/get requests</li> <li>The <code>ServiceTester</code> is used to validate payloads &amp; responses against their expected values</li> </ul> <p>Note</p> <p>This API is a simple example of how to use services packaged with pesto in python scripts. We encourage you to copy/paste and modify the classes should you feel the need for specific use cases, but both this and <code>pesto test</code> is not designed for robustness and scalability</p> <p>We consider the target of <code>pesto test</code> capabilities to be the data scientist, integration testing &amp; scalability should be done at production level</p>"},{"location":"pesto_build.html","title":"<code>pesto build</code> : Package an algorithm","text":"<p>When your project is properly configured (cf. pesto init), PESTO can build a docker image containing a running web service.</p>"},{"location":"pesto_build.html#basic-usage","title":"Basic usage","text":"<p>If your project path is <code>PESTO_PROJECT_ROOT = /path/to/your/workspace/xxx-service</code> you can build it using :</p> <pre><code>pesto build {PESTO_PROJECT_ROOT}\n</code></pre> <p>It creates a packaged docker image:</p> <p>xxx-service:1.0.0.dev0</p> <p>By default, the build command use configuration files in the following directories :</p> <pre><code>xxx-service/pesto/\n\u251c\u2500\u2500 api\n\u2514\u2500\u2500 build\n</code></pre> <p>Note</p> <p>You can find in recipes/docker/pesto-tools a <code>Dockerfile</code> to build a PESTO compliant docker image.</p>"},{"location":"pesto_build.html#note-on-cache","title":"Note on cache","text":"<p>By default, the generated <code>Dockerfile</code> uses no cache.  The main steps of building the docker image are:</p> <ol> <li>PIP configuration and update</li> <li>Install PESTO</li> <li>Install PIP requirements listed in requirements.json</li> <li>Copy algorithm files</li> <li>Set ENV variables and copy algorithm configuration and resources from requirements.json</li> </ol> <p>One can force caching a number of the defined steps, by setting a parameter <code>--cache|-c &lt;VALUE&gt;</code> to the <code>pesto build</code> command:  </p> <pre><code>pesto build {PESTO_PROJECT_ROOT} -c &lt;VALUE&gt;\n</code></pre> <p>The <code>&lt;VALUE&gt;</code> can be:</p> <ul> <li><code>CACHE_UP_TO_PESTO</code> or <code>C1</code>: cache up to step 1</li> <li><code>CACHE_UP_TO_PIP_REQ</code> or <code>C2</code>: cache up to step 2</li> <li><code>CACHE_UP_TO_ALGO</code> or <code>C3</code>: cache up to step 3</li> </ul>"},{"location":"pesto_build.html#profiles","title":"Profiles","text":"<p>In order to accommodate for different hardware targets or slight variations of the same process to deploy, PESTO has a built-in capabilities called <code>profiles</code>.</p>"},{"location":"pesto_build.html#set-profile","title":"Set profile","text":"<p>A profile is a 'tag' that can be added between the base name and the extension of any PESTO configuration file.</p> <p>The profiles json files are named <code>{original_file}.{profile}.json</code>.</p> <p>Example</p> <p>For a <code>description.json</code>, then the corresponding file for the profile <code>gpu</code> would be <code>description.gpu.json</code>.</p> <p>The profile specify which configuration files should be used to create the docker image.  To activate the profile <code>p1</code> at the build, run:  </p> <pre><code>pesto build {PESTO_PROJECT_ROOT} -p p1\n</code></pre> <p>Note</p> <p>Profile <code>.json</code> can be partially complete as they only update the base values if the files are present.</p> <p>Example</p> <ul> <li> <p><code>description.json</code> <pre><code>{\n    \"key\":\"value\", \n    \"key2\":\"value2\"\n}\n</code></pre></p> </li> <li> <p><code>description.p1.json</code> <pre><code>{\n    \"key\":\"value3\"\n}\n</code></pre></p> </li> </ul> <p>Then calling <code>pesto build {PESTO_PROJECT_ROOT} -p p1</code> will generate the <code>description.json</code> <pre><code>{\n    \"key\":\"value3\", \n    \"key2\":\"value2\"\n}\n</code></pre></p>"},{"location":"pesto_build.html#check-profile","title":"Check profile","text":"<p>PESTO provides some helper libraries to detect which profile was used during packaging.</p> <pre><code>from pesto.common.pesto import Pesto\nprofile = Pesto.get_profile()\n# ex: profile = 'p1' if activated\n</code></pre> <p>Note</p> <p>This result can be used to adapt the python process to the different profiles.</p>"},{"location":"pesto_build.html#cascading-profiles","title":"Cascading profiles","text":"<p>PESTO profiles can be combined. Basically, PESTO profiles is a list of ordered strings (ex: <code>gpu</code>, <code>stateless</code>) whose .json files in <code>build/api</code> folders sequentially update the base file.</p> <p>To use them, simply add the list of profiles to your PESTO commands: </p> <pre><code>pesto build {PESTO_PROJECT_ROOT} -p p1 p2\n</code></pre> <p>Warning</p> <p>Due to the sequential nature of dictionary updates, the profiles are order dependent</p> <p>The <code>-p p1 p2</code> option tells PESTO to consider, for each configuration file, the following versions :</p> <ul> <li>default : xxx.json (always present)</li> <li>p1 : xxx.p1.json</li> <li>p2 : xxx.p2.json</li> </ul> <p>Warning</p> <p>Profiles do not work recursively yet. Only the root level is compared.</p> <p>Example</p> <ul> <li>xxx.json <pre><code>{\n  \"base\" : \"default\",\n  \"field_0\" : \"default\"\n}\n</code></pre></li> <li>xxx.p1.json <pre><code>{\n  \"field_0\" : \"profile P1\",\n  \"field_1\" : \"profile P1\"\n}\n</code></pre></li> <li>xxx.p2.json <pre><code>{\n  \"field_0\" : \"profile P2\",\n  \"field_2\" : \"profile P2\"\n}\n</code></pre></li> </ul> <p>Will result in the following equivalent <code>xxx.json</code> configuration file : <pre><code>{\n  \"base\" : \"default\",\n  \"field_0\" : \"profile P2\",\n  \"field_1\" : \"profile P1\",\n  \"field_2\" : \"profile P2\"\n}\n</code></pre></p> <p>Note</p> <p>The following files are supported by the cascading profiles rule</p> <pre><code>pesto/api/\n\u251c\u2500\u2500 config.json\n\u251c\u2500\u2500 config_schema.json\n\u251c\u2500\u2500 description.json\n\u251c\u2500\u2500 input_schema.json\n\u251c\u2500\u2500 output_schema.json\n\u2514\u2500\u2500 version.json\npesto/build/\n\u251c\u2500\u2500 requirements.json\n\u2514\u2500\u2500 build.json\n</code></pre>"},{"location":"pesto_build.html#buildjson","title":"build.json","text":"<p>The <code>pesto/build/build.json</code> file is special :</p> <ul> <li>It contains the name and version of the docker image to be built,</li> <li>It does not affect the content of the docker image (only it's name). </li> </ul> <p>The <code>build.json</code> file must be explicitly selected, and is not supported by the cascading profile rule :</p> <pre><code>pesto build {PESTO_PROJECT_ROOT}/pesto/build/build.p2.json -p p1 p2\n</code></pre>"},{"location":"pesto_init.html","title":"<code>pesto init</code> : Create a new packaging project","text":"<p>The first step to package your processing library is to create a new project.</p> <p>In a terminal : <pre><code>$ pesto init /path/to/your/workspace\n</code></pre></p>"},{"location":"pesto_init.html#project-descriptions-fields","title":"Project descriptions fields","text":"<p>You will be prompted for some information to fill the default template.</p> <pre><code>---------------------------------------------------------------------------------------------------------------------------\n  ____  _____ ____ _____ ___        ____                              _                 __            _\n |  _ \\| ____/ ___|_   _/ _ \\   _  |  _ \\ _ __ ___   ___ ___  ___ ___(_)_ __   __ _    / _| __ _  ___| |_ ___  _ __ _   _\n | |_) |  _| \\___ \\ | || | | | (_) | |_) | '__/ _ \\ / __/ _ \\/ __/ __| | '_ \\ / _` |  | |_ / _` |/ __| __/ _ \\| '__| | | |\n |  __/| |___ ___) || || |_| |  _  |  __/| | | (_) | (_|  __/\\__ \\__ \\ | | | | (_| |  |  _| (_| | (__| || (_) | |  | |_| |\n |_|   |_____|____/ |_| \\___/  (_) |_|   |_|  \\___/ \\___\\___||___/___/_|_| |_|\\__, |  |_|  \\__,_|\\___|\\__\\___/|_|   \\__, |\n                                                                              |___/                                 |___/\n-----  ProcESsing facTOry : 1.4.3     -------------------------------------------------------------------------------------\n\nPlease fill necessary information to initialize your template\n\nmaintainer_fullname [pesto]: \nmaintainer_email [pesto@airbus.com]: \nproject_name [algo-service]: xxx-service\nproject_sname [algo-service]: xxx-service\nproject_short_description [Pesto Template contains all the boilerplate you need to create a processing-factory project]: \nproject_version [1.0.0.dev0]: \n\nService generated at /path/to/your/workspace/xxx-service\n</code></pre> <p>The following fields can be set to describe your custom algorithm:</p> <ul> <li>maintainer_fullname</li> <li>maintainer_email</li> <li>project_name</li> <li>project_sname: Project short name</li> <li>project_short_description</li> <li>project_version</li> </ul> <p>This will create a new project named <code>/path/to/your/workspace/xxx-service</code> with the following structure:</p> <pre><code>xxx-service/\n\u251c\u2500\u2500 algorithm\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 input_output.py\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 process.py\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 Makefile\n\u251c\u2500\u2500 MANIFEST.in\n\u251c\u2500\u2500 pesto\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 api\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 build\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 tests\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 setup.py\n</code></pre> <p>Note</p> <p>The project is ready and setup for a simple processing, but you should edit the configuration files to tune PESTO to your needs.</p>"},{"location":"pesto_init.html#custom-template","title":"Custom template","text":"<p>If you have many project sharing some information (your company, email, requirements ...) you can create a specific template.</p> <ul> <li>Copy the default template to a new place for your own template :</li> </ul> <pre><code>$ pip show processing-factory | grep Location | awk '{print $NF}' &gt; /tmp/pesto_site_packages.txt\n$ cp -r `cat /tmp/pesto_site_packages.txt`/pesto_cli/resources/pesto-template /path/to/my_pesto_template\n</code></pre> <ul> <li> <p>Edit your template to fix the default values.</p> </li> <li> <p>Create a new PESTO project using your own template :</p> </li> </ul> <pre><code>$ pesto init -t /path/to/my_pesto_template /path/to/your/workspace/xxx-service\n</code></pre>"},{"location":"pesto_list.html","title":"pesto list","text":"<p>The <code>pesto list</code> command provides the list of available build docker images in the pesto workspace.</p> <pre><code>pesto list\n</code></pre> <p>Example</p> <p>It results the available builds list such as:</p> <pre><code>---------------------------------------------------------------------------------------------------------------------------\n  ____  _____ ____ _____ ___        ____                              _                 __            _\n |  _ \\| ____/ ___|_   _/ _ \\   _  |  _ \\ _ __ ___   ___ ___  ___ ___(_)_ __   __ _    / _| __ _  ___| |_ ___  _ __ _   _\n | |_) |  _| \\___ \\ | || | | | (_) | |_) | '__/ _ \\ / __/ _ \\/ __/ __| | '_ \\ / _` |  | |_ / _` |/ __| __/ _ \\| '__| | | |\n |  __/| |___ ___) || || |_| |  _  |  __/| | | (_) | (_|  __/\\__ \\__ \\ | | | | (_| |  |  _| (_| | (__| || (_) | |  | |_| |\n |_|   |_____|____/ |_| \\___/  (_) |_|   |_|  \\___/ \\___\\___||___/___/_|_| |_|\\__, |  |_|  \\__,_|\\___|\\__\\___/|_|   \\__, |\n                                                                              |___/                                 |___/\n-----  ProcESsing facTOry : 1.4.3     -------------------------------------------------------------------------------------\n\nProcessing Factory repository path :\n\nlist of available builds :\n\n algo-service:1.0.0.dev0 :\n            pesto build algo-service:1.0.0.dev0\n\n algo-service:1.0.0.dev0-stateful :\n            pesto build algo-service:1.0.0.dev0-stateful\n</code></pre>"},{"location":"pesto_run.html","title":"<code>pesto run</code> : Run the packaged algorithm","text":"<p>Once the processing library is built, it can be run. The <code>pesto run</code> command comes with 2 variants which are described below.</p>"},{"location":"pesto_run.html#pesto-run-docker","title":"pesto run docker","text":"<p>This variant starts the service container, calls the <code>process</code> endpoint with the provided payload and writes the  result at the provided output location. Once done, it stops the container.</p> <pre><code>Usage: pesto run docker [OPTIONS] PAYLOAD DOCKER_IMAGE OUTPUT_PATH\n\n  (Experimental) Run a pesto algorithm in a docker. Work only for stateless\n  services. Payload can be a path to a posix file or a json string\n\nArguments:\nPAYLOAD       [required]\nDOCKER_IMAGE  [required]\nOUTPUT_PATH   [required]\n\nOptions:\n--host-volume-path TEXT             Volume to be mounted from host\n--image-volume-path TEXT            Where the volume is mounted in image\n--nvidia / --no-nvidia              use nvidia runtime  [default: no-nvidia]\n--ssl / --no-ssl                    run with SSL  [default: no-ssl]\n--network TEXT                      Network driver to be used  [default: host]\n--web-service / --no-web-service    Run the docker in WS mode, true by default. \n                                    Otherwise processing is exec in container after start  [default: web-service]\n--help                              Show this message and exit.\n</code></pre> <p>Example: <pre><code>pesto run docker '{\"image\":\"file:///opt/algo-service/pesto/tests/resources/test_1/input/image.png\"}' algo-service:1.0.0.dev0 /tmp/output_pesto.json\n</code></pre></p> <p>If the payload references files that are not already in the image container (as in the example given), it is required to specify host and image volume path to be mounted as parameters.</p>"},{"location":"pesto_run.html#pesto-run-local","title":"pesto run local","text":"<p>This variant can be used to run the algorithm locally. It requires to have pesto, the algorithm and all its dependencies installed at system level, which is not an easy setup. Alternatively, it can be used within the container image which already meet this requirement.  The interest is then to save on the initialisation time of the container and execute several runs within the container once started.</p> <pre><code>Usage: pesto run local [OPTIONS] PAYLOAD OUTPUT_PATH\n\n  (Experimental) Run a pesto algorithm locally (not in docker). Payload can be\n  a path to a posix file or a json string, or an url\n\nArguments:\n  PAYLOAD      [required]\n  OUTPUT_PATH  [required]\n\nOptions:\n  --help  Show this message and exit.\n</code></pre> <p>Examples: Either from your local environment: <pre><code>pesto run local '{\"image\":\"file:///opt/algo-service/pesto/tests/resources/test_1/input/image.png\"}' /tmp/result.txt\n</code></pre></p> <p>Or from inside the container that has been generated: <pre><code>docker run -it --rm -v /tmp:/tmp algo-service:1.0.0.dev0 bash -c \"pesto run local '{\\\"image\\\":\\\"file:///opt/algo-service/pesto/tests/resources/test_1/input/image.png\\\"}' /tmp/result.txt\"```\n</code></pre></p>"},{"location":"pesto_run.html#note-on-ssl","title":"Note on SSL","text":"<p>The service can be started in <code>https</code> mode. For instance: <pre><code>pesto run docker --ssl '{\"image\":\"file:///opt/algo-service/pesto/tests/resources/test_1/input/image.png\"}' algo-service:1.0.0.dev0 /tmp/output_pesto.json\n</code></pre> or </p> <p><pre><code>docker run --rm -p 4000:8080 -e PESTO_USE_SSL='true' algo-service:1.0.0.dev0\n</code></pre> This should start the container so that it can be accessed from <code>https://localhost:4000/api/v1</code></p> <p>There are various ways to handle the certificates. They should be available in the docker image as <code>/etc/pesto/ssl/cert.pem</code> and <code>/etc/pesto/ssl/key.pem</code>.</p>"},{"location":"pesto_run.html#method-1-pesto-generated-certificate","title":"Method 1: PESTO generated certificate","text":"<p>By default, some self-signed certificates are generated and deployed in the docker image under <code>/etc/pesto/ssl/</code>. The certificate validity must be ignored in this case as it is not issued from a valid Certificate Authority.</p>"},{"location":"pesto_run.html#method-2-self-generated-certificate","title":"Method 2: self generated certificate","text":"<p>You can also use your own certificate (generated with mkcert or openssl for instance).</p> <p>Once generated you must make an archive of the certificate and key and declare it as a requirement. <pre><code># generate the cert and key\n...\n# put them in an archive for PESTO requirements\ntar czf ssl.tar.gz cert.pem key.pem\n</code></pre></p> <p>Declare the resulting archive as a requirement in <code>requirements.json</code> (update the <code>from</code> path): <pre><code>{\n  \"environments\": {\n  },\n  \"requirements\": {\n    \"ssl\": {\n      \"from\": \"file:///path/to/your/ssl.tar.gz\",\n      \"to\": \"/etc/pesto/ssl/\"\n    }\n  },\n  \"dockerBaseImage\": \"python:3.8-buster\"\n}\n</code></pre></p>"},{"location":"pesto_run.html#method-3-lets-encrypt-certificate","title":"Method 3: Let's Encrypt certificate","text":"<p>You need to get a DNS domain registered and follow the instructions from Let's Encrypt documentation.</p> <p>You can then add your key and certificate: <pre><code>tar czf ssl.tar.gz cert.pem key.pem\n</code></pre></p> <p>Declare the resulting archive as a requirement in <code>requirements.json</code> (update the <code>from</code> path): <pre><code>{\n  \"environments\": {\n  },\n  \"requirements\": {\n    \"ssl\": {\n      \"from\": \"file:///path/to/your/ssl.tar.gz\",\n      \"to\": \"/etc/pesto/ssl/\"\n    }\n  },\n  \"dockerBaseImage\": \"python:3.8-buster\"\n}\n</code></pre></p>"},{"location":"pesto_schemagen.html","title":"<code>pesto schemagen</code> : Generate the input/output schemas","text":"<p>PESTO's webservice needs the <code>pesto/api/input_schema.json</code> and <code>pesto/api/output_schema.json</code> files to specify the input and output formats of the algorithm. The schemas must match with the <code>Process.process()</code> function signature. It can be laborious to specify valid schemas that are perfectly aligned with the function signature. The <code>schemagen</code> action of <code>pesto</code> generates the input and output schemas for you.</p> <p>To generate the <code>pesto/api/input_schema.json</code> and <code>pesto/api/output_schema.json</code> files, simply run: <pre><code>pesto schemagen /path/to/your/workspace/xxx-service\n</code></pre></p> <p>Success</p> <pre><code>...\nThe Input schema is now in algo-service/pesto/api/input_schema.json\nThe Output schema is now in algo-service/pesto/api/output_schema.json\n</code></pre> <p>The input and output files contain the schemas:</p> <p>Input and output schemas</p> Input schemaOutput schema input_schema.json<pre><code>{\n    \"image\": {\n        \"$ref\": \"#/definitions/Image\",\n        \"description\": \"Input image\"\n    },\n    ...\n    \"string_parameter\": {\n        \"type\": \"string\",\n        \"description\": \"A string parameter\"\n    },\n    \"required\": [\n        \"image\"\n    ]\n}\n</code></pre> output_schema.json<pre><code>{\n    \"image\": {\n        \"$ref\": \"#/definitions/Image\"\n    },\n    \"areas\": {\n        \"$ref\": \"#/definitions/Polygons\"\n    },\n    ...\n    \"image_list\": {\n        \"$ref\": \"#/definitions/Images\"\n    }\n}\n</code></pre> <p>Important</p> <ul> <li>Remember to run <code>pesto schemagen</code> every time you change <code>algorithm/input_output.py</code></li> <li>The input and output files are left intact if already existing. Use <code>--force</code> to overwrite the files.</li> </ul> <p>Remember to run <code>schemagen --force</code> every time you change your files so that the function's signature and the schemas are synched. <pre><code>pesto schemagen --force /path/to/your/workspace/xxx-service\n</code></pre></p>"},{"location":"pesto_schemagen.html#input-and-output-dataclasses","title":"Input and Output dataclasses","text":"<p>To benefit from the <code>schemagen</code> action, you need to :</p> <ul> <li>encapsulated the input parameters in the <code>Input</code> class</li> <li>encapsulate the return objects in the <code>Output</code> class</li> <li>use the <code>process(input: Input) -&gt; Output</code> signature</li> </ul> <p>The <code>Input</code> and <code>Output</code> class must be python dataclasses:</p> input_output.py<pre><code>from dataclasses import dataclass\nfrom pesto.cli.fields import Definition, field, definition, user_definition\nimport numpy as np\nfrom typing import List\n\n@dataclass\nclass Input:\n    image:np.array = definition(Definition.Image, required=True, description=\"Input image\")\n    dict_parameter:dict = definition(Definition.Metadata, description=\"A dict parameter\")\n    integer_parameter: int = field(\"A (integer) number parameter\")\n    ...\n\n@dataclass\nclass Output:\n    integer_output: int\n    string_output:str = field()\n    image_list: List[np.array] = definition(Definition.Images, description=\"The output images\")\n    geojson:object = user_definition(\"geojson\")\n    ...\n</code></pre> <p>Each field has its schema inferred from it's python type or definition.</p>"},{"location":"pesto_schemagen.html#json-schema-inference","title":"JSON Schema inference","text":""},{"location":"pesto_schemagen.html#from-a-python-type","title":"From a python type","text":"<p>A typed field is enough to infer the json schema. Supported python types are</p> <ul> <li><code>str</code> : mapped to a json string field</li> <li><code>int</code> : mapped to a json integer field</li> <li><code>float</code> : mapped to a json number field</li> </ul> <p>Example: input_output.py<pre><code>@dataclass\nclass Input:\n    integer_output: int\n    string_output:str\n</code></pre></p> <p>To attach documentation, simply use the <code>field()</code> function. This description will go to the json schema. input_output.py<pre><code>@dataclass\nclass Input:\n    integer_parameter: int = field(\"An integer parameter\")\n</code></pre></p>"},{"location":"pesto_schemagen.html#from-a-pesto-definitions","title":"From a PESTO Definitions","text":"<p>PESTO definitions are standard reusable structures.</p> <p>Supported PESTO Definitions are:</p> <ul> <li><code>Image</code> : a numpy array</li> <li><code>Images</code> : a list of <code>Image</code></li> <li><code>Polygon</code> : a geojson <code>Polygon</code> geometry</li> <li><code>Polygons</code> : a list of <code>Polygon</code></li> <li><code>Metadata</code> : a generic json object</li> <li><code>Metadatas</code> : a list of <code>Metadata</code></li> </ul> <p>Example for defining an image field with its description: input_output.py<pre><code>@dataclass\nclass Input:\n    image:np.array = definition(Definition.Image, description=\"The output image\")\n</code></pre></p>"},{"location":"pesto_schemagen.html#from-a-user-defined-definitions","title":"From a user defined Definitions","text":"<p>You also can define your own definitions and use them in the <code>input_output.py</code> file. </p> <p>Add your definition in the <code>api/user_definitions.json</code> file: api/user_definitions.json<pre><code>{\n    \"object_parameter\": {\n        \"description\": \"A dict parameter with more spec, of the form {'key':'value'}\",\n        \"type\": \"object\",\n        \"properties\": {\n            \"key\": {\n                \"type\": \"string\"\n            }\n        }\n    }\n}\n</code></pre></p> <p>Then use the definition in <code>input_output.py</code> : input_output.py<pre><code>@dataclass\nclass Output:\n    geojson:object = user_definition(\"object_parameter\")\n</code></pre></p>"},{"location":"pesto_schemagen.html#schemagen-checklist","title":"<code>Schemagen</code> checklist","text":"<p>Checklist</p> <p>In order to make sure that schemagen can generate the input and output schema files, remember the following rules:</p> <ul> <li>The algorithm signature is <code>process(input: Input) -&gt; Output</code></li> <li>The <code>Input</code> and <code>Output</code> classes are annotated with <code>@dataclass</code> (they are therefore python dataclasses)</li> <li>The input_output.py class is a correct python file</li> <li>if you generate the schemas, remember to use <code>--force</code> to overwrite the existing files</li> </ul>"},{"location":"pesto_test.html","title":"<code>pesto test</code> : Test the packaged algorithm","text":"<p>PESTO integrate a minimal yet powerful testing framework.</p> <p>You must first configure your <code>pesto/tests/resources</code> folder by creating a new <code>my_test_data</code> folder inside:</p> <pre><code>tests\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 resources/\n \u00a0\u00a0 \u251c\u2500\u2500 expected_describe.json\n \u00a0\u00a0 \u2514\u2500\u2500 my_test_data/\n</code></pre> <p>The <code>pesto/tests/resources/my_test_data</code> must contains :</p> <ul> <li>input : list of files to create the processing payload</li> <li>output : list of files to create the expected dictionary response from the processing</li> </ul> <p>The <code>input</code> and <code>output</code> directories both describes a json payload (the processing input and output). Each filename <code>key.type</code> in those folders must match an entry in its corresponding <code>*_schema.json</code> :</p> <p>key.type files</p> <p><code>key</code> is the variable name of the input/output</p> <p><code>type</code> is the primitive type of the key :</p> <ul> <li><code>*.string</code>, <code>*.float</code>, <code>*.int</code></li> <li><code>*.json</code> : dictionaries</li> <li><code>*.tif</code>, <code>*.jpg</code>, <code>*.png</code> for images.</li> <li>arrays can be constructed using a folder <code>key</code> containing its enumerated items (<code>1.int</code>, <code>2.int</code>, ...)</li> </ul> <p>Example</p> <pre><code>my_test_data\n\u251c\u2500\u2500 input\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dict_parameter.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 image.png\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 integer_parameter.int\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 number_parameter.float\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 object_parameter.json\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 string_parameter.string\n\u2514\u2500\u2500 output\n    \u251c\u2500\u2500 areas\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 0.json\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 1.json\n    \u251c\u2500\u2500 dict_output.json\n    \u251c\u2500\u2500 geojson.json\n    \u251c\u2500\u2500 image_list\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 0.png\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 1.png\n    \u251c\u2500\u2500 image.png\n    \u251c\u2500\u2500 integer_output.integer\n    \u251c\u2500\u2500 number_output.float\n    \u2514\u2500\u2500 string_output.string\n</code></pre> <p>json payload</p> <pre><code>pesto/tests/resources/my_test_data/input\n\u251c\u2500\u2500 key1.string (containing 'text')\n\u251c\u2500\u2500 key2.int (containing '33')\n\u2514\u2500\u2500 key3.float (containing '3.14')\n</code></pre> <p>Results in the following 'input' payload:</p> <pre><code>{\n    \"key1\" : \"text\",\n    \"key2\" : 33,\n    \"key3\" : 3.14\n}\n</code></pre> <p>Then, make sure that <code>pesto/tests/test_service.py</code> contains a test pointing to your <code>my_test_data</code> folder.</p> <p>Finally, run the following command :</p> pestopytest  (alternative) <pre><code>$ pesto test /path/to/service-xxx\n</code></pre> <pre><code>$ pytest /path/to/service-xxx/pesto/tests\n</code></pre> <pre><code>Usage: pesto test [OPTIONS] BUILD_CONFIG\n\n  Test algorithm from given build.json\n\nArguments:\n  BUILD_CONFIG  [required]\n\nOptions:\n  -p, --profile TEXT      Select specific files to update\n  --nvidia / --no-nvidia  Run docker with nvidia runtime  [default: no-nvidia]\n  --ssl / --no-ssl        run with SSL  [default: no-ssl]\n  -n, --network TEXT      Define a specific network t run docker\n  --help                  Show this message and exit.\n</code></pre> <p>Note</p> <p><code>pesto test</code> is designed not to fail if the requests pass. Instead, it will simply compare dictionaries and display /   save the differences as well as the responses, so that the user can go look at what happened and check if this is correct.</p> <p><code>pesto test</code> should be used for debug purposed and not for unit test purposes.</p> <p>In basic template, two test are implemented (<code>test_1</code> &amp; <code>test_2</code>) with two images and their output. They successfully pass as:</p> <pre><code>---------------------------------------------------------------------------------------------------------------------------\n  ____  _____ ____ _____ ___        ____                              _                 __            _\n |  _ \\| ____/ ___|_   _/ _ \\   _  |  _ \\ _ __ ___   ___ ___  ___ ___(_)_ __   __ _    / _| __ _  ___| |_ ___  _ __ _   _\n | |_) |  _| \\___ \\ | || | | | (_) | |_) | '__/ _ \\ / __/ _ \\/ __/ __| | '_ \\ / _` |  | |_ / _` |/ __| __/ _ \\| '__| | | |\n |  __/| |___ ___) || || |_| |  _  |  __/| | | (_) | (_|  __/\\__ \\__ \\ | | | | (_| |  |  _| (_| | (__| || (_) | |  | |_| |\n |_|   |_____|____/ |_| \\___/  (_) |_|   |_|  \\___/ \\___\\___||___/___/_|_| |_|\\__, |  |_|  \\__,_|\\___|\\__\\___/|_|   \\__, |\n                                                                              |___/                                 |___/\n-----  ProcESsing facTOry : 1.4.3     -------------------------------------------------------------------------------------\n\n[ ... ]\n\nINFO     | pesto.common.testing.test_runner:run_all:108 - --- Tests Results ---\nINFO     | pesto.common.testing.test_runner:run_all:109 - {\n  \"describe\": {\n    \"NoDifference\": true\n  },\n  \"test_1\": {\n    \"NoDifference\": true\n  },\n  \"test_2\": {\n    \"NoDifference\": true\n  }\n}\nINFO     | pesto.common.testing.test_runner:run_all:110 - --- Copying tests outputs to /tmp/pesto/tests/algo-service/1.0.0.dev0\n</code></pre>"},{"location":"tutorial_pytorch.html","title":"Deploying PyTorch in Python via a REST API with PESTO","text":"<p>Abstract</p> <p>This tutorial is inspired from the official Deploying PyTorch in Python via a REST API with Flask tutorial. </p> <p>In this walkthrough, you will be guided in using PESTO for packaging your Deep Learning Model such that it is ready for deployment in production. You will be able to send processing requests to your newly created web service embedding your own inference model.</p> <p>This model is a Resnet 50 CNN trained on ImageNet, and takes as input an image and returns one of the 1000 imagenet classes.</p> <p>During this tutorial you will learn to</p> <ul> <li>Package a model using PESTO</li> <li>Define the input and output API of you web service</li> <li>Generate the web service Docker image</li> <li>Deploy your webservice</li> <li>Send requests &amp; get responses from the service</li> </ul>"},{"location":"tutorial_pytorch.html#install-pesto","title":"Install PESTO","text":"<p>First, ensure you have PESTO installed in a python 3.6+ environment. Typically, you can use Miniconda as a virtual env.</p> <p>Note</p> <p>You should have docker community edition installed and configured in your machine. Refer to the docker documentation for more details.</p> <p>To install PESTO with pip (see Get Started): </p> <pre><code>$ pip install processing-factory\n</code></pre>"},{"location":"tutorial_pytorch.html#create-pesto-project","title":"Create PESTO project","text":"<p>Next, initialize your PESTO project in the desired repository.</p> <pre><code>$ pesto init {PESTO_root_projects_repository_path}\n</code></pre> <p>You are prompted for some information to fill the default template. Here's an example of the display</p> <pre><code>---------------------------------------------------------------------------------------------------------------------------\n  ____  _____ ____ _____ ___        ____                              _                 __            _\n |  _ \\| ____/ ___|_   _/ _ \\   _  |  _ \\ _ __ ___   ___ ___  ___ ___(_)_ __   __ _    / _| __ _  ___| |_ ___  _ __ _   _\n | |_) |  _| \\___ \\ | || | | | (_) | |_) | '__/ _ \\ / __/ _ \\/ __/ __| | '_ \\ / _` |  | |_ / _` |/ __| __/ _ \\| '__| | | |\n |  __/| |___ ___) || || |_| |  _  |  __/| | | (_) | (_|  __/\\__ \\__ \\ | | | | (_| |  |  _| (_| | (__| || (_) | |  | |_| |\n |_|   |_____|____/ |_| \\___/  (_) |_|   |_|  \\___/ \\___\\___||___/___/_|_| |_|\\__, |  |_|  \\__,_|\\___|\\__\\___/|_|   \\__, |\n                                                                              |___/                                 |___/\n-----  ProcESsing facTOry : 1.4.3     -------------------------------------------------------------------------------------\n\nPlease fill necessary information to initialize your template\n\nmaintainer_fullname [pesto]: Computer Vision\nmaintainer_email [pesto@airbus.com]: computervision@airbus.com\nproject_name [algo-service]: pytorch-deployment-tutorial\nproject_sname [pytorch-deployment-tutorial]:                            \nproject_short_description [Pesto Template contains all the boilerplate you need to create a processing-factory project]: My first deployment with PESTO\nproject_version [1.0.0.dev0]: 1.0.0\n[2022-12-13 17:44:24,345] 28731-INFO app::init():l44:\nService generated at /tmp/pesto/pytorch-deployment-tutorial\n</code></pre> <p>It generates the default template in a folder <code>pytorch-deployment-tutorial</code> with the following file structure:</p> <pre><code>pytorch-deployment-tutorial/\n\u251c\u2500\u2500 algorithm\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 input_output.py\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 process.py\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 Makefile\n\u251c\u2500\u2500 MANIFEST.in\n\u251c\u2500\u2500 pesto\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 api\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 build\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 tests\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 setup.py\n</code></pre> <p>You can recognize a python package with a package named <code>algorithm</code> and a module <code>algorithm.process</code>. The main processing is defined here (in Python and using your custom libraries if you want to do so)</p> <p>The folder <code>pesto</code> includes the necessary resources to build the docker image containing the service:</p> <ul> <li><code>pesto/api</code> will specify the input/output of our process in terms of RESTful API</li> <li><code>pesto/build</code> will specify resources, docker images, etc ... so that PESTO can build the service with the correct dependencies</li> <li><code>pesto/test</code> will contains resources to test &amp; debug your service once built as well as helper scripts to use </li> </ul>"},{"location":"tutorial_pytorch.html#your-custom-processing-code","title":"Your Custom Processing code","text":"<p>Tip</p> <p>Due to the way we will load pesto-defined files in our process.py, (as well as custom dependencies unpacked at specific locations), it is hard to locally test the custom processing code without rewriting part of it to work locally. This is a known difficulty in development, we recommend to wrap your codebase under a custom library or package and to write as little code as possible (loading models, calling the prediction library then formatting the result properly) under process.py</p> <p>First, we will specify our inference pipeline. Our objective is to use a pretrained Convolutional Neural Network (A Resnet50) from <code>torchvision</code> to predict classes for image that will be fed to it.</p> <p>The model was trained on ImageNet so it should return one amongst 1000 classes when presented with an image.</p> <p>We will load our model, using the included checkpoints loading function of torchvision, as well as a json file containing the conversion between class indexes and class names (which is stored in <code>/etc/pesto/config.json</code>, more on that later).</p> <pre><code>import json\nimport torchvision.models\n\nwith open(os.path.join(\"/etc/pesto/\", \"config.json\"), 'r') as f:\n    IMAGENET_CLASS_INDEX = json.load(f)\n\n# Make sure to pass `pretrained` as `True` to use the pretrained weights:\nMODEL = models.alexnet(pretrained=True)\n# Since we are using our model only for inference, switch to `eval` mode:\nMODEL.eval()\n</code></pre> <p>Resnet model requires the image to be of 3 channel RGB image of size 224 x 224. We will preprocess the image with Imagenet values as well.  </p> <p>Info</p> <p>Should you require more information , please refer to the original tutorial as well as the pytorch documentation</p> <pre><code>    from PIL import Image\n    import torchvision.transforms\n    # Preprocessing function\n    def transform_image(image: Image):\n        my_transforms = torchvision.transforms.Compose([\n            torchvision.transforms.Resize(255),\n            torchvision.transforms.CenterCrop(224),\n            torchvision.transforms.ToTensor(),\n            torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])\n        return my_transforms(image).unsqueeze(0)\n</code></pre> <p>Now, getting predictions from this model is simple:</p> <pre><code>import time \n\ndef predict(image: np.ndarray):\n    \"\"\"\n    The core algorithm is implemented here.\n    \"\"\"\n\n    pil_image = Image.fromarray(image)\n    tensor = transform_image(image=pil_image)\n    outputs = MODEL.forward(tensor)\n    _, y_hat = outputs.max(1)\n    predicted_idx = str(y_hat.item())\n    class_id, class_name = IMAGENET_CLASS_INDEX[predicted_idx]\n\n    result = {'category': class_name, 'time'}\n\n    return result\n</code></pre> <p>Now we will need to put these functions so that PESTO can properly call them.</p> <p>Look at <code>algorithm/process.py</code>. This is the module that will be loaded by PESTO inside our server and which will be called during preprocessing. </p> <p>There is a <code>Process</code> class with <code>on_start()</code> and <code>process()</code> methods.</p> <p>The <code>on_start()</code> method will be called on the first processing request, it is usually useful to load resources etc.</p> <p>The <code>process()</code> function is called during call to <code>/api/v1/process</code>, when we want to actually process input data</p> <p>We want to integrate our previous code into this structure, so your <code>algorithm/process.py</code> file should look like this (replace the existing <code>process.py</code> file by this code, or write your own)</p> <p>Note</p> <p>We did not load the Model in the <code>Process</code> class so each method inside the <code>Process</code> class is static. </p> process.py<pre><code>import json\nimport os\n\nimport numpy as np\nimport torch.cuda\nimport torchvision.models\nimport torchvision.transforms\nfrom PIL import Image\n\nfrom algorithm.input_output import Input, Output\n\n# Device Agnostic Code\nif torch.cuda.is_available():\n    device = torch.device('cuda')\n    cpu = torch.device('cpu')\nelse:\n    device = torch.device('cpu')\n    cpu = torch.device('cpu')\n\n\n# Load Classes\nwith open(os.path.join(\"/etc/pesto/\", \"config.json\"), \"r\") as f:\n    IMAGENET_CLASS_INDEX = json.load(f)\n\n# Load Model\n\n# Make sure to pass `pretrained` as `True` to use the pretrained weights:\nMODEL = torchvision.models.resnet50(pretrained=True)\n\nif torch.cuda.is_available():\n    MODEL = MODEL.to(device)\n\n# Since we are using our model only for inference, switch to `eval` mode:\nMODEL.eval()\n\n\nclass Process:\n    @staticmethod\n    def on_start() -&gt; None:\n        \"\"\"\n        Process.on_start will be called at server start time.\n        If you need to load heavy resources before processing data, this should be done here.\n        \"\"\"\n        image = (np.random.random((256, 256, 3)) * 255.0).astype(np.uint8)\n        image = Image.fromarray(image)\n        tensor = Process.transform_image(image).to(device)\n        _ = MODEL.forward(tensor)\n        print(\"DUMMY RUN OK\")\n\n    # Preprocessing function\n    @staticmethod\n    def transform_image(image: Image):\n        my_transforms = torchvision.transforms.Compose(\n            [\n                torchvision.transforms.Resize(255),\n                torchvision.transforms.CenterCrop(224),\n                torchvision.transforms.ToTensor(),\n                torchvision.transforms.Normalize(\n                    [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n                ),\n            ]\n        )\n        return my_transforms(image).unsqueeze(0)\n\n    # Main processing function\n    @staticmethod\n    def process(input: Input) -&gt; Output:\n        \"\"\"\n        The core algorithm is implemented here.\n        \"\"\"\n\n        # PESTO gives images as C,H,W so we will convert them back to H,W,C to convert them as PIL.Image\n        image = input.image.transpose((1, 2, 0))\n        pil_image = Image.fromarray(image)\n\n        # A tensor with a batch size of 1 (1, C, H, W)\n        tensor = Process.transform_image(image=pil_image)\n\n        if torch.cuda.is_available():\n            tensor = tensor.to(device)\n\n        # Forward\n        outputs = MODEL.forward(tensor)\n\n        if torch.cuda.is_available():\n            outputs = outputs.to(cpu)\n\n        # Postprocess\n        _, y_hat = outputs.max(1)\n        predicted_idx = str(y_hat.item())\n        class_id, class_name = IMAGENET_CLASS_INDEX[predicted_idx]\n\n        return Output(category=class_name)\n</code></pre> input_output.py<pre><code>from dataclasses import dataclass\nfrom pesto.cli.fields import Definition, field, definition, user_definition\nimport numpy as np\n\n@dataclass\nclass Input:\n    image:np.array = definition(Definition.Image, required=True, description=\"Image related to any ImageNet class\")\n\n@dataclass\nclass Output:\n    category:str = field(\"Predicted class\")\n</code></pre> <p>About Images Format</p> <p>PESTO decodes input request in a specific way, which means that for images they are provided to the algorithm in Channel,Height,Width format, contrarily to the usual Height,Width,Channel format. This means that a transposition is required to wrap them up in PIL format for example. </p> <p>The easiest way to do so is to call <code>image = image.transpose((1, 2, 0))</code></p>"},{"location":"tutorial_pytorch.html#generating-the-input-output-schemas","title":"Generating the input &amp; output schemas","text":"<p>PESTO needs the input and output json schemas for specifying the algorithm API to the end users. It can be done by editing the files. However, since we used the <code>Input</code> and <code>Output</code> classes for the <code>process()</code>'s signature, we can benefit from <code>pesto schemagen</code> to generate the schema files:</p> <pre><code>pesto schemagen --force {PESTO_root_projects_repository_path}\n</code></pre> <p>The generated schemas are in <code>api/input_schema.json</code> and in <code>api/output_schema.json</code> :</p> <p>Input and output json schemas</p> InputOutput api/input_schema.json<pre><code>{\n    \"image\": {\n      \"$ref\": \"#/definitions/Image\",\n      \"description\": \"Image related to any ImageNet class\"\n  },\n  \"required\": [\n      \"image\"\n  ]\n}\n</code></pre> api/output_schema.json<pre><code>{\n  \"category\": {\n      \"type\": \"string\",\n      \"description\": \"Predicted class\"\n  },\n  \"required\": []\n}\n</code></pre> <p>Visit the schemagen's checklist to understand how to benefit from the <code>schemagen</code> mechanism.</p>"},{"location":"tutorial_pytorch.html#configuring-the-processing-api-for-our-service","title":"Configuring the Processing API for our service","text":"<p>Now that we have implemented our processing, we will configure the web service API to map the RestAPI with the processing API.</p> <p>Let's have a look at the <code>pesto/api</code> folder :</p> <pre><code>pesto/api/\n\u251c\u2500\u2500 config.json\n\u251c\u2500\u2500 config_schema.json\n\u251c\u2500\u2500 description.json\n\u251c\u2500\u2500 description.stateful.json\n\u251c\u2500\u2500 input_schema.json\n\u251c\u2500\u2500 output_schema.json\n\u251c\u2500\u2500 user_definitions.json\n\u2514\u2500\u2500 version.json\n</code></pre> <ul> <li><code>config.json</code> is a static file which will be available </li> <li><code>config_schema.json</code> is a json schema file that specifies what <code>config.json</code> should look like</li> <li><code>description.json</code> is a json file that contains information about our processing</li> <li><code>input_schema.json</code> is the specification of the input payload that is necessary to run <code>Process.process()</code>. It will be used to specify what should be sent to the webserver</li> <li><code>output_schema.json</code> is the specification of the output response of the processing</li> <li><code>user_definitions.json</code> the user definitions (reusable JSON schema objects)</li> <li><code>description.stateful.json</code> is an alternative description that will be used with a different profile. The later parts of the tutorial will address this point specifically. </li> </ul> <p>For more information on jsonschema please refer to the official documentation</p>"},{"location":"tutorial_pytorch.html#configjson","title":"config.json","text":"<p>In <code>config.json</code> you can put any information that will be used later to configure your algorithm. This can be useful when used in conjunction with profiles, should you have different configuration for different profiles.</p> <p>In our use case, we will simply put all the imagenet classes in this file, so that they are readily acessible by the webservice.</p> <p>Download this file and copy it as <code>config.json</code> </p> <p>Imagenet classes can then be loaded in <code>process.py</code> as follows:</p> process.py<pre><code># Load Classes\nwith open(os.path.join(\"/etc/pesto/\", \"config.json\"), \"r\") as f:\n    IMAGENET_CLASS_INDEX = json.load(f)\n</code></pre> <p>Now we have to define the json schema (<code>config_schema.json</code>) that validates it. Here it is:</p> api/config_schema.json<pre><code>{\n  \"$schema\": \"http://json-schema.org/draft-06/schema#\",\n  \"title\": \"tile-object-detection-config\",\n  \"description\": \"Geo Process API config Schema for Deployment Tutorial\",\n  \"type\": \"object\",\n  \"patternProperties\": {\n    \"^.*$\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"string\"\n      }\n    }\n  }\n}\n</code></pre> <p>Tip</p> <p>You can use the following code snippet to check for json schema validity in python</p> <pre><code>import json\nimport jsonschema\n\nwith open('./config.json', 'r') as f:\nconfig = json.load(f)\n\nwith open('./config_schema.json', 'r') as f:\nschema = json.load(f)\n\njsonschema.validate(config, schema)\n</code></pre>"},{"location":"tutorial_pytorch.html#descriptionjson","title":"description.json","text":"<p>The <code>description.json</code> file contains information that describe your processing. Feel free to fill as much information as possible. Note that those information are INFORMATIVE only and not used anywhere except for the <code>stateful</code> key which has to set. For now, leave it to <code>false</code>, we will come back on it later. </p> <p>Here is an example of a <code>description.json</code> file that you can copy:</p> api/description.json<pre><code>{\n  \"title\": \"pytorch-deployment-tutorial\",\n  \"name\": \"pytorch-deployment-tutorial\",\n  \"version\": \"1.0.0.dev0\",\n  \"description\": \"My first deployment with PESTO\",\n  \"family\": \"classification\",\n  \"template\": \"image-classification\",\n  \"keywords\": [\n    \"classification\",\n    \"resnet\",\n    \"imagenet\"\n  ],\n  \"resources\": {\n    \"cpu\": 4,\n    \"gpu\": 0,\n    \"ram\": 8\n  },\n  \"asynchronous\": false,\n  \"organization\": \"Computer Vision\",\n  \"email\": \"computervision@airbus.com\",\n  \"licence\": \"Property of Computer Vision, all rights reserved\"\n}\n</code></pre>"},{"location":"tutorial_pytorch.html#defining-our-packaging-dependencies","title":"Defining our packaging &amp; dependencies","text":"<p>Now that we have specified our API, let's take on the building part of PESTO.</p> <p>The principle of PESTO is that a <code>Docker</code> image with a webservice containing your processing will be constructed when we call <code>pesto build</code>. The next steps will be configuring PESTO to build a correct docker.</p>"},{"location":"tutorial_pytorch.html#python-dependencies-for-the-project-requirementstxt","title":"Python dependencies for the project &amp; requirements.txt","text":"<p>The project we created is a python package and will be installed as such inside our docker. It is possible to specify the python requirements directly in <code>requirements.txt</code> as it will be parsed when doing <code>pip install {our project}</code></p> <p>The alternative method would be to provide a docker base image with everything already installed, but this is a more advanced usage.</p> <p>For now, the <code>requirements.txt</code> file at the root of our project should look like this:</p> <pre><code>numpy\nPillow\ntorch&gt;=1.5.0\ntorchvision&gt;=0.6.0\n</code></pre> <p>Now let's look at the <code>pesto/build</code> folder</p> <pre><code>build/\n\u251c\u2500\u2500 build.json\n\u251c\u2500\u2500 requirements.cpu.json\n\u2514\u2500\u2500 requirements.json\n</code></pre>"},{"location":"tutorial_pytorch.html#service-name-buildjson","title":"Service Name &amp; build.json","text":"<p>The <code>build.json</code> contains automatically generated information that will be used by PESTO later. You should not have to modify it except if you want to change the version</p> build/build.json<pre><code>{\n  \"name\": \"pytorch-deployment-tutorial\",\n  \"version\": \"1.0.0.dev0\",\n  \"algorithm_path\": null,\n  \"workspace\": null\n}\n</code></pre> <p>The docker image you will generate during build will be tagged <code>name:version</code>.</p>"},{"location":"tutorial_pytorch.html#file-dependencies-requirementsjson","title":"File Dependencies &amp; requirements.json","text":"<p>There are two <code>requirements.json</code> files automatically generated. <code>requirements.gpu.json</code> defines a profile for GPU support and we will see later how to configure it.</p> <p>The <code>requirements.json</code> file default as such</p> requirements.json<pre><code>{\n  \"environments\": {},\n  \"requirements\": {},\n  \"dockerBaseImage\": \"python:3.6-stretch\"\n}\n</code></pre> <p><code>dockerBaseImage</code> is a pointer towards a docker image that will be used to build the webservice. PESTO will inherit from this base image to install itself as well as the process and its dependencies. For now, <code>python:3.6-stretch</code> is a good starting point as it contains the necessary resources installed. You can pass a custom docker image to this step, provided your docker client can access it.</p> <p><code>environments</code> is used to set environment variables. We will set the <code>$TORCH_HOME</code> environment variable to ensure we know its location. The <code>$TORCH_HOME</code> variable is used by <code>torchvision</code> to download weights in specific locations, check the torch Hub documentation for more details </p> <pre><code>  \"environments\": {\n    \"TORCH_HOME\": \"/opt/torch/\"\n  }\n</code></pre> <p><code>requirements</code> is helpful to add static resources such as model weights, configs, as well as custom python package. For now, <code>requirements</code> support two types of resources:</p> <ul> <li>static resources inside <code>.tar.gz</code> archives that will be uncompressed in environment</li> <li>python wheel <code>.whl</code> files that can be pip installed</li> </ul> <p>In order to try ourselves this mechanism, we will download the weights for our model. Torchvision models automatically do this by default when the models are called if the weights are not in <code>$TORCH_HOME</code>, but in our case we will put the weights ourselves so that no download step is done during runtime</p> <p>First, download this file</p> <pre><code>wget https://download.pytorch.org/models/resnet50-19c8e357.pth\n</code></pre> <p>Then put it into a <code>.tar.gz</code> archive accessible via either a uri (<code>file://</code>), or an url (<code>gs://</code> and <code>http://</code> are supported for now). Note that if you would deploy a model into production we recommend uploading resources to a server or committing them alongside your project so that everything is 100% reproducible</p> <pre><code>tar -zcvf checkpoint.tar.gz resnet50-19c8e357.pth\n</code></pre> <p>Now, note the uri of this <code>checkpoint.tar.gz</code>. We want to uncompress this file in <code>/opt/torch/checkpoints/</code> in our docker. So your requirements file will look like:</p> build/requirements.json<pre><code>{\n  \"environments\": {\n    \"TORCH_HOME\": \"/opt/torch/\"\n  },\n  \"requirements\": {\n    \"checkpoints\": {\n      \"from\": \"file://{PATH_TO_ARCHIVE}/checkpoint.tar.gz\",\n      \"to\": \"/opt/torch/checkpoints/\"\n    }\n  },\n  \"dockerBaseImage\": \"python:3.6-stretch\"\n}\n</code></pre>"},{"location":"tutorial_pytorch.html#building-the-service","title":"Building the Service","text":"<p>Now we have everything we need to build our service. The building part is simple:</p> <p><code>pesto build {root of your project}/pytorch-deployment-tutorial</code></p> <p>There will be a lot of logging informing you about what is happening. PESTO is using <code>/home/$USER/.pesto/{process name}/{process version}</code> to store resources needed to build the docker containing the service.</p> <p>Example in our case:</p> <pre><code>pytorch-deployment-tutorial/\n\u2514\u2500\u2500 1.0.0.dev0\n    \u251c\u2500\u2500 checkpoints\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 resnet50-19c8e357.pth\n    \u251c\u2500\u2500 dist\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 pesto_cli-1.0.0rc1-py3-none-any.whl\n    \u251c\u2500\u2500 Dockerfile\n    \u251c\u2500\u2500 pesto\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 api_geo_process_v1.0.yaml\n    \u251c\u2500\u2500 pytorch-deployment-tutorial\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 algorithm\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 process.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 Makefile\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 MANIFEST.in\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 pesto\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 api\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 config.json\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 config_schema.json\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 description.json\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 input_schema.json\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 output_schema.json\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 service.json\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 version.json\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 build\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 build.json\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 requirements.json\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 tests\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u251c\u2500\u2500 (...)\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 README.md\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 requirements.txt\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 setup.py\n    \u2514\u2500\u2500 requirements\n        \u2514\u2500\u2500 checkpoint.tar.gz\n</code></pre> <p>If docker build fails you can debug your service directly in this folder.</p> <p>If the build succeeds you should be able to see your image <code>docker image ls</code>:</p> <pre><code>REPOSITORY                   TAG          IMAGE ID       CREATED        SIZE\npytorch-deployment-tutorial  1.0.0.dev0   08342775a658   4 minutes ago  3.48GB\n</code></pre>"},{"location":"tutorial_pytorch.html#testing-and-usage","title":"Testing and Usage","text":"<p>Now we want to test if everything goes well, which means:</p> <ul> <li>Launching the docker container and checking that it responds to http requests</li> <li>Checking that the process we just deployed is working correctly</li> </ul> <p>Fortunately, PESTO features a test/usage framework which is the purpose of the <code>pesto/test</code> folder</p>"},{"location":"tutorial_pytorch.html#booting-up-the-container-first-http-requests","title":"Booting up the container &amp; first http requests","text":"<p>First, we can verify that we are able to start the container and send very basic requests to it; </p> <p>Run <code>docker run --rm -p 4000:8080 pytorch-deployment-tutorial:1.0.0.dev0</code> (check the docker documentation should you need help about the various arguments)</p> <p>This should start the container so that it can be accessed from http://localhost:4000.</p> <p>In your browser (or using CURL) you can send basic GET requests to your container, such as</p> <ul> <li> <p>http://localhost:4000/api/v1/health (<code>CURL -X GET http://localhost:4000/api/v1/health</code>) with should answer \"OK\"</p> </li> <li> <p>http://localhost:4000/api/v1/describe (<code>CURL -X GET http://localhost:4000/api/v1/describe</code>) which should return a json file</p> </li> </ul> <p>It is recommended that you save said json file, it will be used later on <code>CURL -X GET http://localhost:4000/api/v1/describe &gt; description.json</code></p> <p>Now the question is: How can I send a properly formated processing request with the payload (my image) that I want to send ?</p> <p>Tip</p> <p>If you know all about base64 encoding or sending URI with POST requests, feel free to skip this part.</p> <p>For the next parts you can safely stop your running container</p>"},{"location":"tutorial_pytorch.html#defining-test-resources","title":"Defining Test Resources","text":"<p>Let's take a look at the <code>pesto/test</code> directory</p> <pre><code>tests\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 resources/\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 expected_describe.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 test_1/\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 test_2/\n</code></pre> <p>The <code>resources</code> folder will be used by the PESTO Test API and be converted to processing requests that will be sent to <code>/api/v1/process</code> with the right format. The response will then be compared to the expected response, and act as unit tests. </p> <p>Note</p> <p>In the later part of this tutorial we will showcase three different ways of generating processing payloads and getting responses / comparing to expected responses. Each method can be used in different context, using different abstraction levels.</p> <p>The first file of interest is the <code>expected_describe.json</code>. This file will be compared to the <code>http://localhost:4000/api/v1/describe</code> json document returned by the API. This description file can be used to parse the information about the API (input / output schema, description etc...)</p> <p>You will learn in time how to manually create an <code>expected_describe.json</code> from the <code>pesto/api</code> folder, for now it is best to copy the <code>describe.json</code> file that we generated earlier and to put it as <code>expected_describe.json</code>. You can compare this file to the default <code>expected_describe.json</code> and notice how the differences translate themselves to the default processing</p> <p>Now, there are several folders named <code>test_*</code>. The purpose of these test folders is that the input payload files are deposited in <code>input</code> and the expected response is in <code>output</code></p> <p>Let's take a look at the test folder:</p> <pre><code>test_1\n\u251c\u2500\u2500 input\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dict_parameter.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 image.png\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 integer_parameter.int\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 number_parameter.float\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 object_parameter.json\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 string_parameter.string\n\u2514\u2500\u2500 output\n    \u251c\u2500\u2500 areas\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 0.json\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 1.json\n    \u251c\u2500\u2500 dict_output.json\n    \u251c\u2500\u2500 geojson.json\n    \u251c\u2500\u2500 image_list\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 0.png\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 1.png\n    \u251c\u2500\u2500 image.png\n    \u251c\u2500\u2500 integer_output.integer\n    \u251c\u2500\u2500 number_output.float\n    \u2514\u2500\u2500 string_output.string\n</code></pre> <p>You can see that both input and output have files with extension corresponding to input types. The filenames are matched with the json payload keys.</p> <p>Now, we are going to write two tests with those two images as input:</p> <p></p> <p>We know that the input key is <code>image</code> and the output key is <code>category</code> the model should predict  <code>{\"category\": \"Egyptian_cat\"}</code></p> <p></p> <p>We know that the input key is <code>image</code> and the output key is <code>category</code> the model should predict  <code>{\"category\": \"mortar\"}</code></p> <p>So, your folder structure should now look like:</p> <pre><code>tests/\n\u251c\u2500\u2500 resources\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 expected_describe.json\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 test_1 (cat)\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 input\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 image.png &lt;- copy the cat image here\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 output\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0     \u2514\u2500\u2500 category.string &lt;- this should be Egypcatian_cat\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 test_2 (pesto)\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 input\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 image.jpg &lt;- copy the pesto image here\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 output\n\u2502\u00a0\u00a0         \u2514\u2500\u2500 category.string &lt;- this should be mortar\n</code></pre>"},{"location":"tutorial_pytorch.html#using-pesto-test-command","title":"Using <code>pesto test</code> command","text":"<p>The first way of testing your service is to call <code>pesto test</code> utility the same way you called <code>pesto build</code>. In order, this command will:</p> <ul> <li>Run the docker container (the same way we did previously)</li> <li>Send requests to <code>api/v1/describe</code> and compare with the <code>expected_describe.json</code></li> <li>Send process payloads to <code>api/v1/process</code> and compare them to the desired outputs</li> </ul> <p>In your project root, run <code>pesto test .</code> and check what happens. The logs should show different steps being processed.</p> <p>You can check the responses and differences between dictionnaries in the .pesto workspace: <code>/home/$USER/.pesto/tests/pytorch-deployment-tutorial/1.0.0.dev0</code></p> <p>You will find there the results / responses of all the requests, including describes and processings requests. This is a useful folder to debug potential differences.</p> <p>Should everything goes well, the <code>results.json</code> file should look like this</p> results.json<pre><code>{\n  \"describe\": {\n    \"NoDifference\": true\n  },\n  \"test_1\": {\n    \"NoDifference\": true\n  },\n  \"test_2\": {\n    \"NoDifference\": true\n  }\n}\n</code></pre> <p>Note</p> <p><code>pesto test</code> is designed not to fail if the requests pass; Instead it will simply compare dictionaries and display / save the differences as well as the responses, so that the user can go look at what happened and check if this is correct. <code>pesto test</code> should be used for debug purposed and not for unit test purposes. We will see later how we can use the PESTO test API with pytest to actually run unit tests</p>"},{"location":"tutorial_pytorch.html#bonus-using-pytest-unit-testing","title":"Bonus: Using Pytest &amp; unit testing","text":"<p>Once you're sure and have debugged properly you can write or edit unit tests in <code>PESTO_PROJECT_ROOT/tests/</code> (check the autogenerated file <code>tests/test_service.py</code> ) and run it with <code>pytest tests</code> on your root project</p> <p>This can be used to ensure non regression on further edits or if you want to do test driver development</p>"},{"location":"tutorial_pytorch.html#bonus-using-pesto-python-api-to-run-tests-send-requests-to-model","title":"Bonus: Using PESTO Python API to run tests &amp; send requests to model","text":"<p>Should you want to use in a non-scalable way or further test your services, you can have a look at the <code>{PESTO_PROJECT_ROOT}/scripts/example_api_usage.py</code> file that exposes the low level python API that is used in <code>pesto test</code></p> <ul> <li>The <code>ServiceManager</code> class is the class used as a proxy for the python Docker API, and is used to pull / run /attach / stop the containers</li> <li>The <code>PayloadGenerator</code> class is used to translate files to actual json payload for the REST API</li> <li>The <code>EndpointManager</code> manages the various endpoints of the processes, and act as a front to post/get requests</li> <li>The <code>ServiceTester</code> is used to validate payloads &amp; responses against their expected values</li> </ul> <p>Note</p> <p>This API is a simple example of how to use services packaged with pesto in python scripts. We encourage you to copy/paste and modify the classes should you feel the need for specific use cases, but both this and <code>pesto test</code> is not designed for robustness and scalability</p> <p>We consider the target of <code>pesto test</code> capabilities to be the data scientist, integration testing &amp; scalability should be done at production level</p>"},{"location":"tutorial_pytorch.html#adding-a-gpu-profile","title":"Adding a GPU profile","text":"<p>In order to create an image with GPU support, we can complete the proposed profile <code>gpu</code>. The file <code>requirements.gpu.json</code> can be updated as follows :</p> requirements.gpu.json<pre><code>{\n  \"environments\": {},\n  \"requirements\": {},\n  \"dockerBaseImage\": \"pytorch/pytorch:1.5-cuda10.1-cudnn7-runtime\"\n}\n</code></pre> <p>You can now build your GPU enabled microservice :</p> <p><code>pesto build {root of your project}/pytorch-deployment-tutorial -p gpu</code></p>"},{"location":"tutorial_pytorch.html#pesto-profiles","title":"PESTO Profiles","text":"<p>in order to accomodate for different hardware targets or slight variations of the same process to deploy, PESTO has a built-in capabilities called <code>profiles</code></p> <p>Basically, PESTO profiles is a  list of ordered strings (<code>gpu stateless</code>) whose .json files in <code>build/api</code> folders sequentially update the base file.</p> <p>To use them, simply add the list of profiles to your PESTO commands: <code>pesto build {PESTO_PROJECT_ROOT} -p p1 p2</code> or <code>pesto test {PESTO_PROJECT_ROOT} -p p1 p2</code></p> <p>The profiles json files are named <code>{original_file}.{profile}.json</code>.</p> <p>For example, for a <code>description.json</code>, then the corresponding description.json for the profile gpu would be <code>description.gpu.json</code>.</p> <p>Profile jsons can be partially complete as they only update the base values if the files are present.</p> <p>Example:</p> <p><code>description.json</code>: <code>{\"key\":\"value\", \"key2\":\"value2\"}</code> <code>description.p1.json</code>: <code>{\"key\":\"value3\"}</code></p> <p>Then calling <code>pesto build . -p p1</code> will generate a <code>description.json</code>: <code>{\"key\":\"value3\", \"key2\":\"value2\"}</code> and take all the other files without additionnal profiles.</p> <p>Warning</p> <p>Due to the sequential nature of dictionary updates, the profiles are order dependent</p> <p>If you have a computer with nvidia drivers &amp; a gpu you can try to run <code>pesto build . -p gpu</code> and <code>pesto test . -p gpu --nvidia</code> which should do the same as above but with gpu support (and actually run the process on gpu)</p>"},{"location":"tutorial_pytorch.html#stateful-stateless-services","title":"Stateful &amp; Stateless services","text":"<p>PESTO supports building stateless services as well as stateful services.</p> <p>With stateless services, it is expected that the processing replies directly to the processing request with the response. These services should have no internal state and should always return the same result when presented with the same payload</p> <p>Stateful services can have internal states, and store the processing results to be later queried.</p> <p>The main difference is that sending a processing request to <code>api/v1/process</code> to a stateful service will not return the result but a <code>jobID</code>. The job state can be quiered at <code>GET api/v1/jobs/{jobID}/status</code> and results can be queried at  <code>GET api/v1/jobs/{jobID}/results</code> when the job is done. The response of the latter request will be a json matching the output schema with URI to individual content (that should individually be queried using <code>GET requests</code>)</p> <p></p> <p>Try building your previous service with <code>pesto build . -p stateful</code> and starting it as previously, </p> <p><code>docker run --rm -p 4000:8080 pytorch-deployment-tutorial:1.0.0.dev0-stateful</code></p> <p>Then, run the API usage script (<code>python scripts/example_api_usage</code>) while having modified the image name to stateful.</p> <p>This script should send several requests (like pesto test), but the advantage is that it doesn't kill the service afterwards, so it is possible to look at what happened:</p> <ul> <li>Try doing a get request on <code>/api/v1/jobs/</code> you should see a list of jobs</li> <li>Grab a job id then do a GET request on <code>/api/v1/jobs/{jobID}/status</code>. It should be \"DONE\"</li> <li>Then do a GET request on <code>/api/v1/jobs/{jobID}/results</code> to get results</li> </ul> <p>You should get something like</p> <pre><code>{\n  \"category\": \"http://localhost:4000/api/v1/jobs/1080019533/results/category\"\n}\n</code></pre> <p>A GET request on the aforementioned URL should return <code>Egyptian_cat</code> or <code>mortar</code></p>"},{"location":"tutorial_pytorch.html#next-steps","title":"Next Steps","text":"<p>The rest of the documentation should be more accessible now that you have completed this tutorial</p> <p>Tip</p> <p>You should version your PESTO project using git so that it is reproducible </p> <p>Feel free to send us feedback and ask any question on github</p>"}]}